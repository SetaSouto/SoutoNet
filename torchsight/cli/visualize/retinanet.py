"""Module with commands to visualize the RetinaNet model."""
import click


@click.command()
@click.option('-c', '--checkpoint', type=click.Path(exists=True), required=True,
              help='The path to the checkpoint generated by a trainer.')
@click.option('-d', '--dataset', default='coco', show_default=True, type=click.Choice(['coco', 'logo32plus', 'flickr32']))
@click.option('-dr', '--dataset-root', type=click.Path(exists=True), required=True,
              help='The path to the directory where is the data of the dataset.')
@click.option('--subdataset', help='Indicates which dataset inside the given dataset it must use. Default: validation.')
@click.option('--no-shuffle', is_flag=True)
@click.option('--device', help='The device to use to run the model. Default to cuda:0 if cuda is available.')
@click.option('--threshold', default=0.5, show_default=True, help='The confidence threshold for the predictions.')
@click.option('--iou-threshold', default=0.3, show_default=True, help='The threshold for Non Maximum Supresion.')
@click.option('--only-logos', is_flag=True, help='Show only images with logos in the Flickr32 dataset.')
def retinanet(checkpoint, dataset_root, dataset, subdataset, no_shuffle, device, threshold, iou_threshold, only_logos):
    """Visualize the predictions of a RetinaNet model."""
    import random
    import torch
    from torchsight.datasets.flickr32 import Flickr32Dataset
    from torchsight.models.retinanet import RetinaNet
    from torchsight.transforms.augmentation import AugmentDetection
    from torchsight.utils import visualize_boxes

    device = device if device is not None else 'cuda:0' if torch.cuda.is_available() else 'cpu'
    checkpoint = torch.load(checkpoint, map_location=device)
    model = RetinaNet.from_checkpoint(checkpoint, device)
    hyperparameters = checkpoint['hyperparameters']
    transform = AugmentDetection(params=hyperparameters['transform'], evaluation=True)
    transform_visible = AugmentDetection(params=hyperparameters['transform'], evaluation=True, normalize=False)
    params = {'root': dataset_root}

    if dataset == 'flickr32':
        params['dataset'] = subdataset if subdataset is not None else 'test'
        try:
            params['brands'] = hyperparameters['datasets']['flickr32']['brands']
        except KeyError:
            print('WARN: Model was not trained using flickr32 dataset.')
            params['brands'] = None
        dataset = Flickr32Dataset(**params, transform=transform, only_boxes=only_logos)
        dataset_human = Flickr32Dataset(**params, transform=transform_visible)
        label_to_name = dataset.label_to_class
    else:
        raise NotImplementedError()

    indexes = list(range(len(dataset)))

    if not no_shuffle:
        random.shuffle(indexes)

    model.eval(threshold, iou_threshold)
    model.to(device)

    for i in indexes:
        image, *_ = dataset[i]
        image_visible, *_ = dataset_human[i]
        image = image.unsqueeze(dim=0).type(torch.float).to(device)
        detections = model(image)[0]

        visualize_boxes(image_visible, detections, label_to_name)
