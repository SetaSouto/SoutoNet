
--------------------------------------------------------------------------------
 Version 1.0.4 (19th December 2013, by Stefan Romberg, stefan.romberg@informatik.uni-augsburg.de)
--------------------------------------------------------------------------------
  * Made evaluation script fl_eval_classification.py less verbose by default
    to highlight the important scores.
  * New maintainer of this dataset is now Christian Eggert, christian.eggert@informatik.uni-augsburg.de

--------------------------------------------------------------------------------
 Version 1.0.3 (18th November 2013, by Stefan Romberg, stefan.romberg@informatik.uni-augsburg.de)
--------------------------------------------------------------------------------
  * fl_convert-groundtruth.py: added script as example how to read and 
    convert the ground truth files
  * Made evaluation scripts work with Python 2.7 and Python 3.3
  * fixed a few issues with plot functions and newer version of matplotlib
  * fl_eval_retrieval.py:
    - Fixed computation of mean precision and mean recall:
      The mean precision was not computed correctly. The way the mean recall was 
      computed was similar, but due to the dataset structure (an equal number 
      of true positives per query) the outcome was computed correctly.
    IMPORTANT NOTE:
      The usual way *retrieval* systems should be evaluated is by measuring the 
      mean average precision (mAP) which was NOT affected by the issue mentioned 
      above. The usual way *recognition/classification* systems should be 
      evaluated on the FlickrLogos-32 dataset is by measuring *precision/recall*
      as given in 'fl_eval_classification.py' which was NOT affected by the issue 
      mentioned above.
  * Minor clean-up and polishing of all scripts.
  
--------------------------------------------------------------------------------
 Version 1.0.2 (26th April 2013, by Stefan Romberg, stefan.romberg@informatik.uni-augsburg.de)
--------------------------------------------------------------------------------
  * Fixed bug in fl_plot_classification_results.py:
    Labels and values of bar chart were in the wrong order.
    Previously labels of the bar chart were in the order: 
        [Adidas Aldi Apple Becks BMW Carlsberg Chimay Cocacola Corona DHL Erdinger 
        Esso Fedex Ferrari Ford Fosters Google Guiness Heineken HP Milka Nvidia 
        Paulaner Pepsi Rittersport Shell Singha Starbucks Stellaartois Texaco 
        Tsingtao UPS]
    But values of the bar chart were previously in the order: 
        [HP adidas aldi apple becks bmw carlsberg chimay cocacola corona dhl erdinger 
        esso fedex ferrari ford fosters google guiness heineken milka no-logo nvidia 
        paulaner pepsi rittersport shell singha starbucks stellaartois texaco 
        tsingtao ups]
  * fl_read_groundtruth(), fl_read_groundtruth2() now return all classes 
    in lower case. Previously "HP" was returned as "HP", now it is returned as "hp".
    All scripts have been adapted to use lower-case class names internally.
    Double-check your code/data if necessary.
  * The bar chart generated by fl_plot_classification_results.py now shows 
    the actual number of TP and the percentage as text label.
  * Added thumbnail images in <sdk>/testdata/thumbnails for use with example HTML file.
  
--------------------------------------------------------------------------------  
 Version 1.0.1 (26th February 2013, by Stefan Romberg, stefan.romberg@informatik.uni-augsburg.de)
--------------------------------------------------------------------------------
  * Minor changes, better error reporting

--------------------------------------------------------------------------------
 Version 1.0.0 (13th December 2012) by Stefan Romberg, stefan.romberg@informatik.uni-augsburg.de)
--------------------------------------------------------------------------------
  * Initial Release
  