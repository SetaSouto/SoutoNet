<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.5.4" />
<title>torchsight.cli.train.dldenet API documentation</title>
<meta name="description" content="CLI to train the DLDENet." />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.name small{font-weight:normal}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase;cursor:pointer}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title"><code>torchsight.cli.train.dldenet</code> module</h1>
</header>
<section id="section-intro">
<p>CLI to train the DLDENet.</p>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">&#34;&#34;&#34;CLI to train the DLDENet.&#34;&#34;&#34;
import click

from torchsight.trainers import DLDENetTrainer


@click.command()
@click.argument(&#39;dataset-root&#39;, type=click.Path(exists=True))
# Currently we only have the COCO dataset for training
@click.option(&#39;--dataset&#39;, default=&#39;COCO&#39;, show_default=True, type=click.Choice([&#39;COCO&#39;]))
@click.option(&#39;-b&#39;, &#39;--batch-size&#39;, default=8, show_default=True)
@click.option(&#39;--resnet&#39;, default=50, show_default=True, help=&#39;The resnet backbone that the model must use.&#39;)
@click.option(&#39;--logs-dir&#39;, default=&#39;./logs&#39;, type=click.Path(exists=True), show_default=True,
              help=&#39;Where to store the checkpoints and descriptions.&#39;)
@click.option(&#39;-c&#39;, &#39;--checkpoint&#39;, type=click.Path(exists=True), help=&#39;A checkpoint to resume the training from it.&#39;)
@click.option(&#39;--classes&#39;, default=&#39;&#39;,
              help=&#39;Indicate which classes (identified by its string label) must be used for the training. &#39;
              &#39;If no class is provided the trainer will use all the classes. Example: --classes &#34;bear sheep airplane&#34;&#39;)
@click.option(&#39;--optimizer&#39;, default=&#39;adabound&#39;, type=click.Choice([&#39;adabound&#39;, &#39;sgd&#39;]), show_default=True,
              help=&#39;Set the optimizer that the trainer must use to train the model.&#39;)
@click.option(&#39;--not-normalize&#39;, is_flag=True,
              help=&#39;Avoid normalization of the embeddings in the classification module.&#39;)
@click.option(&#39;--device&#39;, default=None, help=&#39;The device that the model must use.&#39;)
def dldenet(dataset_root, dataset, batch_size, resnet, logs_dir, checkpoint, classes, optimizer, not_normalize,
            device):
    &#34;&#34;&#34;Train the DLDENet with weighted classification vectors using the indicated dataset that
    contains is data in DATASET_ROOT directory.

    You can use a checkpoint to resume the training but is not a good practice, because you can change the hyperparams
    of the model get in some troubles like changing the resnet backbone or the number of classes of the model.
    To avoid this you can use the subcommand &#39;dldenet-from-checkpoint&#39; instead.
    &#34;&#34;&#34;
    classes = classes.split()
    n_classes = len(classes) if classes else 80

    DLDENetTrainer(
        hyperparameters={
            &#39;model&#39;: {&#39;resnet&#39;: resnet, &#39;classes&#39;: n_classes, &#39;normalize&#39;: not not_normalize},
            &#39;datasets&#39;: {&#39;root&#39;: dataset_root, &#39;class_names&#39;: classes},
            &#39;dataloaders&#39;: {&#39;batch_size&#39;: batch_size},
            &#39;logger&#39;: {&#39;dir&#39;: logs_dir},
            &#39;checkpoint&#39;: {&#39;dir&#39;: logs_dir},
            &#39;optimizer&#39;: {&#39;use&#39;: optimizer}
        },
        checkpoint=checkpoint,
        device=device
    ).train()


@click.command()
@click.argument(&#39;dataset-root&#39;, type=click.Path(exists=True))
@click.argument(&#39;checkpoint&#39;, type=click.Path(exists=True))
@click.option(&#39;-b&#39;, &#39;--batch-size&#39;, type=click.INT)
@click.option(&#39;--logs-dir&#39;, type=click.Path(exists=True), help=&#39;Where to store the checkpoints and descriptions.&#39;)
@click.option(&#39;--device&#39;, help=&#39;The device that the model must use.&#39;)
def dldenet_from_checkpoint(dataset_root, checkpoint, batch_size, logs_dir, device):
    &#34;&#34;&#34;Get an instance of the trainer from the checkpoint CHECKPOINT and resume the exact same training
    with the dataset that contains its data in DATASET_ROOT.

    You can only change things that will not affect the coherence of the training.
    &#34;&#34;&#34;
    new_params = {&#39;datasets&#39;: {&#39;root&#39;: dataset_root}}

    if batch_size is not None:
        new_params[&#39;dataloaders&#39;] = {&#39;batch_size&#39;: batch_size}
    if logs_dir is not None:
        new_params[&#39;logger&#39;] = {&#39;dir&#39;: logs_dir}
        new_params[&#39;checkpoint&#39;] = {&#39;dir&#39;: logs_dir}

    DLDENetTrainer.from_checkpoint(checkpoint, new_params, device).train()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="torchsight.cli.train" href="index.html">torchsight.cli.train</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.5.4</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>