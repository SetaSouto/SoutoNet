<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.5.4" />
<title>torchsight.trainers.dlde.tracked API documentation</title>
<meta name="description" content="DLDENet trainer for the tracked means version." />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.name small{font-weight:normal}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase;cursor:pointer}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title"><code>torchsight.trainers.dlde.tracked</code> module</h1>
</header>
<section id="section-intro">
<p>DLDENet trainer for the tracked means version.</p>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">&#34;&#34;&#34;DLDENet trainer for the tracked means version.&#34;&#34;&#34;
import time

import torch

from torchsight.models import DLDENetWithTrackedMeans
from torchsight.optimizers import AdaBound
from ..retinanet import RetinaNetTrainer


class DLDENetWithTrackedMeansTrainer(RetinaNetTrainer):
    &#34;&#34;&#34;Deep Local Directional Embedding with tracked means trainer.

    As the architecture is very similar with RetinaNet we use the same trainer and only
    override some attributes and methods. For more information please read the RetinaNet
    trainer documentation.
    &#34;&#34;&#34;
    # Base hyperparameters, can be replaced in the initialization of the trainer
    hyperparameters = {
        &#39;model&#39;: {
            &#39;classes&#39;: 80,
            &#39;resnet&#39;: 18,
            &#39;features&#39;: {
                &#39;pyramid&#39;: 256,
                &#39;regression&#39;: 256,
                &#39;classification&#39;: 256
            },
            &#39;anchors&#39;: {
                &#39;sizes&#39;: [32, 64, 128, 256, 512],
                &#39;scales&#39;: [2 ** 0, 2 ** (1/3), 2 ** (2/3)],
                &#39;ratios&#39;: [0.5, 1, 2]
            },
            &#39;embedding_size&#39;: 256,
            &#39;concentration&#39;: 15,
            &#39;shift&#39;: 0.8,
            # Keep in mind that this thresholds must be the same as in the FocalLoss
            &#39;assignation_thresholds&#39;: {&#39;object&#39;: 0.5, &#39;background&#39;: 0.4},
            &#39;pretrained&#39;: True,
            &#39;evaluation&#39;: {&#39;threshold&#39;: 0.5, &#39;iou_threshold&#39;: 0.5}
        },
        &#39;criterion&#39;: {
            &#39;alpha&#39;: 0.25,
            &#39;gamma&#39;: 2.0,
            &#39;iou_thresholds&#39;: {&#39;background&#39;: 0.4, &#39;object&#39;: 0.5},
            # Weight of each loss. See train method.
            &#39;weights&#39;: {&#39;classification&#39;: 1e3, &#39;regression&#39;: 1}
        },
        &#39;datasets&#39;: {
            &#39;root&#39;: &#39;./datasets/coco&#39;,
            &#39;class_names&#39;: (),  # Empty tuple indicates all classes
            &#39;train&#39;: &#39;train2017&#39;,
            &#39;validation&#39;: &#39;val2017&#39;
        },
        &#39;dataloaders&#39;: {
            &#39;batch_size&#39;: 1,
            &#39;shuffle&#39;: True,
            &#39;num_workers&#39;: 8
        },
        &#39;optimizer&#39;: {
            &#39;use&#39;: &#39;adabound&#39;,  # Which optimizer the trainer must use
            &#39;adabound&#39;: {
                &#39;lr&#39;: 1e-3,  # Learning rate
                &#39;final_lr&#39;: 0.1  # When the optimizer must change from Adam to SGD
            },
            &#39;sgd&#39;: {
                &#39;lr&#39;: 1e-2,
                &#39;momentum&#39;: 0.9,
                &#39;weight_decay&#39;: 1e-4
            }
        },
        &#39;scheduler&#39;: {
            &#39;factor&#39;: 0.1,
            &#39;patience&#39;: 2,
            &#39;threshold&#39;: 0.1
        },
        &#39;transforms&#39;: {
            &#39;resize&#39;: {
                &#39;min_side&#39;: 384,
                &#39;max_side&#39;: 512,
                &#39;stride&#39;: 128
            },
            &#39;normalize&#39;: {
                &#39;mean&#39;: [0.485, 0.456, 0.406],
                &#39;std&#39;: [0.229, 0.224, 0.225]
            }
        }
    }

    def get_model(self):
        &#34;&#34;&#34;Initialize and get a DLDENet model instance.&#34;&#34;&#34;
        hyperparameters = self.hyperparameters[&#39;model&#39;]
        return DLDENetWithTrackedMeans(
            classes=hyperparameters[&#39;classes&#39;],
            resnet=hyperparameters[&#39;resnet&#39;],
            features=hyperparameters[&#39;features&#39;],
            anchors=hyperparameters[&#39;anchors&#39;],
            embedding_size=hyperparameters[&#39;embedding_size&#39;],
            concentration=hyperparameters[&#39;concentration&#39;],
            assignation_thresholds=hyperparameters[&#39;assignation_thresholds&#39;],
            pretrained=hyperparameters[&#39;pretrained&#39;],
            device=self.device
        )

    def get_optimizer(self):
        &#34;&#34;&#34;Returns the optimizer for the training.

        The extended RetinaNetTrainer only has SGD as an optimizer, this trainer also
        includes the [AdaBound optimizer](https://github.com/Luolc/AdaBound) that it&#39;s
        supposed to be as fast as Adam and as good as SGD.

        You can provide the optimizer that you want to use in the &#39;optimizer&#39; hyperparameter
        changing the &#39;use&#39; parameter and providing the name of the one that
        you want to use.

        Returns:
            AdaBound: The adabound optimizer for the training.
        &#34;&#34;&#34;
        params = self.hyperparameters[&#39;optimizer&#39;]
        optimizer = params[&#39;use&#39;].lower()

        if optimizer == &#39;adabound&#39;:
            params = params[&#39;adabound&#39;]
            return AdaBound(self.model.parameters(), lr=params[&#39;lr&#39;], final_lr=params[&#39;final_lr&#39;])

        if optimizer == &#39;sgd&#39;:
            params = params[&#39;sgd&#39;]
            return torch.optim.SGD(self.model.parameters(),
                                   lr=params[&#39;lr&#39;],
                                   momentum=params[&#39;momentum&#39;],
                                   weight_decay=params[&#39;weight_decay&#39;])

        raise ValueError(&#39;Cannot find the parameters for the optimizer &#34;{}&#34;&#39;.format(params[&#39;use&#39;]))

    def forward(self, *args):
        &#34;&#34;&#34;Forward pass through the network and loss computation.

        Returns:
            torch.Tensor: The loss of the batch.
        &#34;&#34;&#34;
        images, annotations, *_ = args
        images, annotations = images.to(self.device), annotations.to(self.device)

        anchors, regressions, classifications = self.model(images, annotations)
        del images

        classification_loss, regression_loss = self.criterion(anchors, regressions, classifications, annotations)
        del anchors, regressions, classifications, annotations

        weights = self.hyperparameters[&#39;criterion&#39;][&#39;weights&#39;]
        classification_loss *= weights[&#39;classification&#39;]
        regression_loss *= weights[&#39;regression&#39;]

        loss = classification_loss + regression_loss

        # Log the classification and regression loss too:
        self.current_log[&#39;Class.&#39;] = float(classification_loss)
        self.current_log[&#39;Regr.&#39;] = float(regression_loss)

        return loss

    def train(self, epochs=100, validate=True):
        &#34;&#34;&#34;Train the model for the given epochs.

        If there is no checkpoint (i.e. checkpoint_epoch == 0) before training we make a loop over the training
        dataset to initialize the means with the random generated embeddings.

        Arguments:
            epochs (int): The number of epochs to train.
            validate (bool): If true it validates the model after each epoch using the validate method.
        &#34;&#34;&#34;
        self.model.to(self.device)
        self.model.train()
        n_batches = len(self.dataloader)

        if self.checkpoint is None:
            # Initialize the means of the classes
            with torch.no_grad():
                start = time.time()
                for batch_index, (images, annotations, *_) in enumerate(self.dataloader):
                    batch_start = time.time()
                    self.model(images.to(self.device), annotations.to(self.device), initializing=True)
                    print(&#39;[Initializing] [Batch {}/{}] [Batch {:.3f} s] [Total {:.3f} s]&#39;.format(
                        batch_index + 1, n_batches, time.time() - batch_start, time.time() - start))
                self.model.update_means()
                print(&#39;[Initializing] Means updated.&#39;)
            # Save the means as checkpoint in the epoch 0
            self.save(0)

        super().train(epochs, validate)

    def epoch_callback(self, epoch):
        &#34;&#34;&#34;Update the means after each epoch.

        Arguments:
            epoch (int): The number of the epoch.
        &#34;&#34;&#34;
        print(&#34;[Training] [Epoch {}] Updating the model&#39;s means.&#34;.format(epoch))
        self.model.update_means()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer"><code class="flex name class">
<span>class <span class="ident">DLDENetWithTrackedMeansTrainer</span></span>
<span>(</span><span><small>ancestors:</small> <a title="torchsight.trainers.retinanet.RetinaNetTrainer" href="../retinanet.html#torchsight.trainers.retinanet.RetinaNetTrainer">RetinaNetTrainer</a>, <a title="torchsight.trainers.trainer.Trainer" href="../trainer.html#torchsight.trainers.trainer.Trainer">Trainer</a>)</span>
</code></dt>
<dd>
<section class="desc"><p>Deep Local Directional Embedding with tracked means trainer.</p>
<p>As the architecture is very similar with RetinaNet we use the same trainer and only
override some attributes and methods. For more information please read the RetinaNet
trainer documentation.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class DLDENetWithTrackedMeansTrainer(RetinaNetTrainer):
    &#34;&#34;&#34;Deep Local Directional Embedding with tracked means trainer.

    As the architecture is very similar with RetinaNet we use the same trainer and only
    override some attributes and methods. For more information please read the RetinaNet
    trainer documentation.
    &#34;&#34;&#34;
    # Base hyperparameters, can be replaced in the initialization of the trainer
    hyperparameters = {
        &#39;model&#39;: {
            &#39;classes&#39;: 80,
            &#39;resnet&#39;: 18,
            &#39;features&#39;: {
                &#39;pyramid&#39;: 256,
                &#39;regression&#39;: 256,
                &#39;classification&#39;: 256
            },
            &#39;anchors&#39;: {
                &#39;sizes&#39;: [32, 64, 128, 256, 512],
                &#39;scales&#39;: [2 ** 0, 2 ** (1/3), 2 ** (2/3)],
                &#39;ratios&#39;: [0.5, 1, 2]
            },
            &#39;embedding_size&#39;: 256,
            &#39;concentration&#39;: 15,
            &#39;shift&#39;: 0.8,
            # Keep in mind that this thresholds must be the same as in the FocalLoss
            &#39;assignation_thresholds&#39;: {&#39;object&#39;: 0.5, &#39;background&#39;: 0.4},
            &#39;pretrained&#39;: True,
            &#39;evaluation&#39;: {&#39;threshold&#39;: 0.5, &#39;iou_threshold&#39;: 0.5}
        },
        &#39;criterion&#39;: {
            &#39;alpha&#39;: 0.25,
            &#39;gamma&#39;: 2.0,
            &#39;iou_thresholds&#39;: {&#39;background&#39;: 0.4, &#39;object&#39;: 0.5},
            # Weight of each loss. See train method.
            &#39;weights&#39;: {&#39;classification&#39;: 1e3, &#39;regression&#39;: 1}
        },
        &#39;datasets&#39;: {
            &#39;root&#39;: &#39;./datasets/coco&#39;,
            &#39;class_names&#39;: (),  # Empty tuple indicates all classes
            &#39;train&#39;: &#39;train2017&#39;,
            &#39;validation&#39;: &#39;val2017&#39;
        },
        &#39;dataloaders&#39;: {
            &#39;batch_size&#39;: 1,
            &#39;shuffle&#39;: True,
            &#39;num_workers&#39;: 8
        },
        &#39;optimizer&#39;: {
            &#39;use&#39;: &#39;adabound&#39;,  # Which optimizer the trainer must use
            &#39;adabound&#39;: {
                &#39;lr&#39;: 1e-3,  # Learning rate
                &#39;final_lr&#39;: 0.1  # When the optimizer must change from Adam to SGD
            },
            &#39;sgd&#39;: {
                &#39;lr&#39;: 1e-2,
                &#39;momentum&#39;: 0.9,
                &#39;weight_decay&#39;: 1e-4
            }
        },
        &#39;scheduler&#39;: {
            &#39;factor&#39;: 0.1,
            &#39;patience&#39;: 2,
            &#39;threshold&#39;: 0.1
        },
        &#39;transforms&#39;: {
            &#39;resize&#39;: {
                &#39;min_side&#39;: 384,
                &#39;max_side&#39;: 512,
                &#39;stride&#39;: 128
            },
            &#39;normalize&#39;: {
                &#39;mean&#39;: [0.485, 0.456, 0.406],
                &#39;std&#39;: [0.229, 0.224, 0.225]
            }
        }
    }

    def get_model(self):
        &#34;&#34;&#34;Initialize and get a DLDENet model instance.&#34;&#34;&#34;
        hyperparameters = self.hyperparameters[&#39;model&#39;]
        return DLDENetWithTrackedMeans(
            classes=hyperparameters[&#39;classes&#39;],
            resnet=hyperparameters[&#39;resnet&#39;],
            features=hyperparameters[&#39;features&#39;],
            anchors=hyperparameters[&#39;anchors&#39;],
            embedding_size=hyperparameters[&#39;embedding_size&#39;],
            concentration=hyperparameters[&#39;concentration&#39;],
            assignation_thresholds=hyperparameters[&#39;assignation_thresholds&#39;],
            pretrained=hyperparameters[&#39;pretrained&#39;],
            device=self.device
        )

    def get_optimizer(self):
        &#34;&#34;&#34;Returns the optimizer for the training.

        The extended RetinaNetTrainer only has SGD as an optimizer, this trainer also
        includes the [AdaBound optimizer](https://github.com/Luolc/AdaBound) that it&#39;s
        supposed to be as fast as Adam and as good as SGD.

        You can provide the optimizer that you want to use in the &#39;optimizer&#39; hyperparameter
        changing the &#39;use&#39; parameter and providing the name of the one that
        you want to use.

        Returns:
            AdaBound: The adabound optimizer for the training.
        &#34;&#34;&#34;
        params = self.hyperparameters[&#39;optimizer&#39;]
        optimizer = params[&#39;use&#39;].lower()

        if optimizer == &#39;adabound&#39;:
            params = params[&#39;adabound&#39;]
            return AdaBound(self.model.parameters(), lr=params[&#39;lr&#39;], final_lr=params[&#39;final_lr&#39;])

        if optimizer == &#39;sgd&#39;:
            params = params[&#39;sgd&#39;]
            return torch.optim.SGD(self.model.parameters(),
                                   lr=params[&#39;lr&#39;],
                                   momentum=params[&#39;momentum&#39;],
                                   weight_decay=params[&#39;weight_decay&#39;])

        raise ValueError(&#39;Cannot find the parameters for the optimizer &#34;{}&#34;&#39;.format(params[&#39;use&#39;]))

    def forward(self, *args):
        &#34;&#34;&#34;Forward pass through the network and loss computation.

        Returns:
            torch.Tensor: The loss of the batch.
        &#34;&#34;&#34;
        images, annotations, *_ = args
        images, annotations = images.to(self.device), annotations.to(self.device)

        anchors, regressions, classifications = self.model(images, annotations)
        del images

        classification_loss, regression_loss = self.criterion(anchors, regressions, classifications, annotations)
        del anchors, regressions, classifications, annotations

        weights = self.hyperparameters[&#39;criterion&#39;][&#39;weights&#39;]
        classification_loss *= weights[&#39;classification&#39;]
        regression_loss *= weights[&#39;regression&#39;]

        loss = classification_loss + regression_loss

        # Log the classification and regression loss too:
        self.current_log[&#39;Class.&#39;] = float(classification_loss)
        self.current_log[&#39;Regr.&#39;] = float(regression_loss)

        return loss

    def train(self, epochs=100, validate=True):
        &#34;&#34;&#34;Train the model for the given epochs.

        If there is no checkpoint (i.e. checkpoint_epoch == 0) before training we make a loop over the training
        dataset to initialize the means with the random generated embeddings.

        Arguments:
            epochs (int): The number of epochs to train.
            validate (bool): If true it validates the model after each epoch using the validate method.
        &#34;&#34;&#34;
        self.model.to(self.device)
        self.model.train()
        n_batches = len(self.dataloader)

        if self.checkpoint is None:
            # Initialize the means of the classes
            with torch.no_grad():
                start = time.time()
                for batch_index, (images, annotations, *_) in enumerate(self.dataloader):
                    batch_start = time.time()
                    self.model(images.to(self.device), annotations.to(self.device), initializing=True)
                    print(&#39;[Initializing] [Batch {}/{}] [Batch {:.3f} s] [Total {:.3f} s]&#39;.format(
                        batch_index + 1, n_batches, time.time() - batch_start, time.time() - start))
                self.model.update_means()
                print(&#39;[Initializing] Means updated.&#39;)
            # Save the means as checkpoint in the epoch 0
            self.save(0)

        super().train(epochs, validate)

    def epoch_callback(self, epoch):
        &#34;&#34;&#34;Update the means after each epoch.

        Arguments:
            epoch (int): The number of the epoch.
        &#34;&#34;&#34;
        print(&#34;[Training] [Epoch {}] Updating the model&#39;s means.&#34;.format(epoch))
        self.model.update_means()</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer.hyperparameters"><code class="name">var <span class="ident">hyperparameters</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer.epoch_callback"><code class="name flex">
<span>def <span class="ident">epoch_callback</span></span>(<span>self, epoch)</span>
</code></dt>
<dd>
<section class="desc"><p>Update the means after each epoch.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>epoch</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of the epoch.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def epoch_callback(self, epoch):
    &#34;&#34;&#34;Update the means after each epoch.

    Arguments:
        epoch (int): The number of the epoch.
    &#34;&#34;&#34;
    print(&#34;[Training] [Epoch {}] Updating the model&#39;s means.&#34;.format(epoch))
    self.model.update_means()</code></pre>
</details>
</dd>
<dt id="torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer.get_model"><code class="name flex">
<span>def <span class="ident">get_model</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize and get a DLDENet model instance.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_model(self):
    &#34;&#34;&#34;Initialize and get a DLDENet model instance.&#34;&#34;&#34;
    hyperparameters = self.hyperparameters[&#39;model&#39;]
    return DLDENetWithTrackedMeans(
        classes=hyperparameters[&#39;classes&#39;],
        resnet=hyperparameters[&#39;resnet&#39;],
        features=hyperparameters[&#39;features&#39;],
        anchors=hyperparameters[&#39;anchors&#39;],
        embedding_size=hyperparameters[&#39;embedding_size&#39;],
        concentration=hyperparameters[&#39;concentration&#39;],
        assignation_thresholds=hyperparameters[&#39;assignation_thresholds&#39;],
        pretrained=hyperparameters[&#39;pretrained&#39;],
        device=self.device
    )</code></pre>
</details>
</dd>
<dt id="torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer.get_optimizer"><code class="name flex">
<span>def <span class="ident">get_optimizer</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns the optimizer for the training.</p>
<p>The extended RetinaNetTrainer only has SGD as an optimizer, this trainer also
includes the <a href="https://github.com/Luolc/AdaBound">AdaBound optimizer</a> that it's
supposed to be as fast as Adam and as good as SGD.</p>
<p>You can provide the optimizer that you want to use in the 'optimizer' hyperparameter
changing the 'use' parameter and providing the name of the one that
you want to use.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>AdaBound</code></strong></dt>
<dd>The adabound optimizer for the training.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_optimizer(self):
    &#34;&#34;&#34;Returns the optimizer for the training.

    The extended RetinaNetTrainer only has SGD as an optimizer, this trainer also
    includes the [AdaBound optimizer](https://github.com/Luolc/AdaBound) that it&#39;s
    supposed to be as fast as Adam and as good as SGD.

    You can provide the optimizer that you want to use in the &#39;optimizer&#39; hyperparameter
    changing the &#39;use&#39; parameter and providing the name of the one that
    you want to use.

    Returns:
        AdaBound: The adabound optimizer for the training.
    &#34;&#34;&#34;
    params = self.hyperparameters[&#39;optimizer&#39;]
    optimizer = params[&#39;use&#39;].lower()

    if optimizer == &#39;adabound&#39;:
        params = params[&#39;adabound&#39;]
        return AdaBound(self.model.parameters(), lr=params[&#39;lr&#39;], final_lr=params[&#39;final_lr&#39;])

    if optimizer == &#39;sgd&#39;:
        params = params[&#39;sgd&#39;]
        return torch.optim.SGD(self.model.parameters(),
                               lr=params[&#39;lr&#39;],
                               momentum=params[&#39;momentum&#39;],
                               weight_decay=params[&#39;weight_decay&#39;])

    raise ValueError(&#39;Cannot find the parameters for the optimizer &#34;{}&#34;&#39;.format(params[&#39;use&#39;]))</code></pre>
</details>
</dd>
<dt id="torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self, epochs=100, validate=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Train the model for the given epochs.</p>
<p>If there is no checkpoint (i.e. checkpoint_epoch == 0) before training we make a loop over the training
dataset to initialize the means with the random generated embeddings.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>epochs</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of epochs to train.</dd>
<dt><strong><code>validate</code></strong> :&ensp;<code>bool</code></dt>
<dd>If true it validates the model after each epoch using the validate method.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def train(self, epochs=100, validate=True):
    &#34;&#34;&#34;Train the model for the given epochs.

    If there is no checkpoint (i.e. checkpoint_epoch == 0) before training we make a loop over the training
    dataset to initialize the means with the random generated embeddings.

    Arguments:
        epochs (int): The number of epochs to train.
        validate (bool): If true it validates the model after each epoch using the validate method.
    &#34;&#34;&#34;
    self.model.to(self.device)
    self.model.train()
    n_batches = len(self.dataloader)

    if self.checkpoint is None:
        # Initialize the means of the classes
        with torch.no_grad():
            start = time.time()
            for batch_index, (images, annotations, *_) in enumerate(self.dataloader):
                batch_start = time.time()
                self.model(images.to(self.device), annotations.to(self.device), initializing=True)
                print(&#39;[Initializing] [Batch {}/{}] [Batch {:.3f} s] [Total {:.3f} s]&#39;.format(
                    batch_index + 1, n_batches, time.time() - batch_start, time.time() - start))
            self.model.update_means()
            print(&#39;[Initializing] Means updated.&#39;)
        # Save the means as checkpoint in the epoch 0
        self.save(0)

    super().train(epochs, validate)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="torchsight.trainers.retinanet.RetinaNetTrainer" href="../retinanet.html#torchsight.trainers.retinanet.RetinaNetTrainer">RetinaNetTrainer</a></b></code>:
<ul class="hlist">
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.__init__" href="../trainer.html#torchsight.trainers.trainer.Trainer.__init__">__init__</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.backward" href="../retinanet.html#torchsight.trainers.retinanet.RetinaNetTrainer.backward">backward</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.batch_callback" href="../trainer.html#torchsight.trainers.trainer.Trainer.batch_callback">batch_callback</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.eval" href="../retinanet.html#torchsight.trainers.retinanet.RetinaNetTrainer.eval">eval</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.forward" href="../retinanet.html#torchsight.trainers.retinanet.RetinaNetTrainer.forward">forward</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.from_checkpoint" href="../trainer.html#torchsight.trainers.trainer.Trainer.from_checkpoint">from_checkpoint</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.get_criterion" href="../retinanet.html#torchsight.trainers.retinanet.RetinaNetTrainer.get_criterion">get_criterion</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.get_dataloaders" href="../retinanet.html#torchsight.trainers.retinanet.RetinaNetTrainer.get_dataloaders">get_dataloaders</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.get_datasets" href="../retinanet.html#torchsight.trainers.retinanet.RetinaNetTrainer.get_datasets">get_datasets</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.get_logger" href="../trainer.html#torchsight.trainers.trainer.Trainer.get_logger">get_logger</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.get_scheduler" href="../retinanet.html#torchsight.trainers.retinanet.RetinaNetTrainer.get_scheduler">get_scheduler</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.get_transform" href="../retinanet.html#torchsight.trainers.retinanet.RetinaNetTrainer.get_transform">get_transform</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.resume" href="../trainer.html#torchsight.trainers.trainer.Trainer.resume">resume</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.save" href="../trainer.html#torchsight.trainers.trainer.Trainer.save">save</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.validate" href="../trainer.html#torchsight.trainers.trainer.Trainer.validate">validate</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="torchsight.trainers.dlde" href="index.html">torchsight.trainers.dlde</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer" href="#torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer">DLDENetWithTrackedMeansTrainer</a></code></h4>
<ul class="">
<li><code><a title="torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer.epoch_callback" href="#torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer.epoch_callback">epoch_callback</a></code></li>
<li><code><a title="torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer.get_model" href="#torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer.get_model">get_model</a></code></li>
<li><code><a title="torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer.get_optimizer" href="#torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer.get_optimizer">get_optimizer</a></code></li>
<li><code><a title="torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer.hyperparameters" href="#torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer.hyperparameters">hyperparameters</a></code></li>
<li><code><a title="torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer.train" href="#torchsight.trainers.dlde.tracked.DLDENetWithTrackedMeansTrainer.train">train</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.5.4</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>