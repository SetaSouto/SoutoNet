<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.5.4" />
<title>torchsight.trainers.retinanet API documentation</title>
<meta name="description" content="RetinaNet Trainer." />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.name small{font-weight:normal}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase;cursor:pointer}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title"><code>torchsight.trainers.retinanet</code> module</h1>
</header>
<section id="section-intro">
<p>RetinaNet Trainer.</p>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">&#34;&#34;&#34;RetinaNet Trainer.&#34;&#34;&#34;
import torch
from torch.optim.lr_scheduler import ReduceLROnPlateau

from torchsight import utils
from torchsight.optimizers import AdaBound

from ..datasets import CocoDataset, Flickr32Dataset, Logo32plusDataset
from ..losses import FocalLoss
from ..models import RetinaNet
from ..transforms.augmentation import AugmentDetection
from .trainer import Trainer


class RetinaNetTrainer(Trainer):
    &#34;&#34;&#34;RetinaNet trainer class.&#34;&#34;&#34;
    # Base hyperparameters, can be replaced in the initialization of the trainer:
    # &gt;&gt;&gt; RetinaNetTrainer(hyperparameters={&#39;RetinaNet&#39;: {&#39;classes&#39;: 1}})
    hyperparameters = {
        &#39;model&#39;: {
            &#39;resnet&#39;: 50,
            &#39;features&#39;: {
                &#39;pyramid&#39;: 256,
                &#39;regression&#39;: 256,
                &#39;classification&#39;: 256
            },
            &#39;anchors&#39;: {
                &#39;sizes&#39;: [32, 64, 128, 256, 512],
                &#39;scales&#39;: [2 ** 0, 2 ** (1/3), 2 ** (2/3)],
                &#39;ratios&#39;: [0.5, 1, 2]
            },
            &#39;pretrained&#39;: True,
            &#39;evaluation&#39;: {
                &#39;threshold&#39;: 0.5,
                &#39;iou_threshold&#39;: 0.5
            }
        },
        &#39;criterion&#39;: {
            &#39;alpha&#39;: 0.25,
            &#39;gamma&#39;: 2.0,
            &#39;iou_thresholds&#39;: {
                &#39;background&#39;: 0.4,
                &#39;object&#39;: 0.5
            },
            &#39;increase_foreground_by&#39;: 1e3,
            # Weight of each loss. See train method.
            &#39;weights&#39;: {&#39;classification&#39;: 1e3, &#39;regression&#39;: 1}
        },
        &#39;datasets&#39;: {
            &#39;use&#39;: &#39;coco&#39;,
            &#39;coco&#39;: {
                &#39;root&#39;: &#39;./datasets/coco&#39;,
                &#39;class_names&#39;: (),  # () indicates all classes
                &#39;train&#39;: &#39;train2017&#39;,
                &#39;validation&#39;: &#39;val2017&#39;
            },
            &#39;logo32plus&#39;: {
                &#39;root&#39;: &#39;./datasets/logo32plus&#39;,
                &#39;classes&#39;: None,
            },
            &#39;flickr32&#39;: {
                &#39;root&#39;: &#39;./datasets/flickr32&#39;,
                &#39;brands&#39;: None,
                &#39;only_boxes&#39;: True,
                &#39;training&#39;: &#39;trainval&#39;,  # The name of the dataset to use for training
                &#39;validation&#39;: &#39;test&#39;  # The name of the dataset to use for validation
            }
        },
        &#39;dataloaders&#39;: {
            &#39;batch_size&#39;: 1,
            &#39;shuffle&#39;: True,
            &#39;num_workers&#39;: 1
        },
        &#39;optimizer&#39;: {
            &#39;use&#39;: &#39;sgd&#39;,  # Which optimizer the trainer must use
            &#39;adabound&#39;: {
                &#39;lr&#39;: 1e-3,  # Learning rate
                &#39;final_lr&#39;: 1  # When the optimizer change from Adam to SGD
            },
            &#39;sgd&#39;: {
                &#39;lr&#39;: 1e-2,
                &#39;momentum&#39;: 0.9,
                &#39;weight_decay&#39;: 1e-4
            }
        },
        &#39;scheduler&#39;: {
            &#39;factor&#39;: 0.1,
            &#39;patience&#39;: 5,
            &#39;threshold&#39;: 0.01
        },
        &#39;transform&#39;: {
            &#39;GaussNoise&#39;: {
                &#39;var_limit&#39;: (10, 50),
                &#39;p&#39;: 0.5
            },
            &#39;GaussianBlur&#39;: {
                &#39;blur_limit&#39;: 0.7,
                &#39;p&#39;: 0.5
            },
            &#39;RandomBrightnessContrast&#39;: {
                &#39;brightness_limit&#39;: 0.2,
                &#39;contrast_limit&#39;: 0.2,
                &#39;p&#39;: 0.5
            },
            &#39;Rotate&#39;: {
                &#39;limit&#39;: 45,
                &#39;p&#39;: 0.5
            },
            &#39;LongestMaxSize&#39;: {
                &#39;max_size&#39;: 512
            },
            &#39;PadIfNeeded&#39;: {
                &#39;min_height&#39;: 512,
                &#39;min_width&#39;: 512
            },
            &#39;RandomSizedBBoxSafeCrop&#39;: {
                &#39;height&#39;: 512,
                &#39;width&#39;: 512
            }
        }
    }

    ####################################
    ###           GETTERS            ###
    ####################################

    def get_transform(self):
        &#34;&#34;&#34;Initialize and get the transforms for the images.

        Arguments:
            params (dict): The dict with the params for the transforms.
                It must have &#39;resize&#39; and &#39;normalize&#39; args values.

        Returns:
            torchvision.transform.Compose: The Compose of the transformations.
        &#34;&#34;&#34;
        return AugmentDetection(params=self.hyperparameters[&#39;transform&#39;])

    def get_datasets(self):
        &#34;&#34;&#34;Initialize and get the Coco datasets for training and evaluation.

        Returns:
            tuple: A Tuple with the torch.utils.data.Datasets for training and validation.
        &#34;&#34;&#34;
        transform = self.get_transform()

        params = self.hyperparameters[&#39;datasets&#39;]
        dataset = params[&#39;use&#39;]

        if dataset == &#39;coco&#39;:
            params = params[&#39;coco&#39;]

            n_classes = len(params[&#39;class_names&#39;])
            n_classes = 80 if n_classes == 0 else n_classes
            self.hyperparameters[&#39;model&#39;][&#39;classes&#39;] = n_classes

            return (CocoDataset(root=params[&#39;root&#39;],
                                dataset=params[&#39;train&#39;],
                                classes_names=params[&#39;class_names&#39;],
                                transform=transform),
                    CocoDataset(root=params[&#39;root&#39;],
                                dataset=params[&#39;validation&#39;],
                                classes_names=params[&#39;class_names&#39;],
                                transform=transform))

        if dataset == &#39;logo32plus&#39;:
            params = params[&#39;logo32plus&#39;]
            num_classes = len(params[&#39;classes&#39;]) if params[&#39;classes&#39;] is not None else 32

            self.hyperparameters[&#39;model&#39;][&#39;classes&#39;] = num_classes

            return (Logo32plusDataset(**params, dataset=&#39;training&#39;, transform=transform),
                    Logo32plusDataset(**params, dataset=&#39;validation&#39;, transform=transform))

        if dataset == &#39;flickr32&#39;:
            params = params[&#39;flickr32&#39;]
            num_classes = len(params[&#39;brands&#39;]) if params[&#39;brands&#39;] is not None else 32

            self.hyperparameters[&#39;model&#39;][&#39;classes&#39;] = num_classes

            kwargs = {
                &#39;root&#39;: params[&#39;root&#39;],
                &#39;brands&#39;: params[&#39;brands&#39;],
                &#39;only_boxes&#39;: params[&#39;only_boxes&#39;],
                &#39;transform&#39;: transform
            }

            return (Flickr32Dataset(**kwargs, dataset=params[&#39;training&#39;]),
                    Flickr32Dataset(**kwargs, dataset=params[&#39;validation&#39;]))

    def get_dataloaders(self):
        &#34;&#34;&#34;Initialize and get the dataloaders for the datasets.

        Returns:
            torch.utils.data.Dataloaders: The dataloader for the training dataset.
            torch.utils.data.Dataloaders: The dataloader for the validation dataset.
        &#34;&#34;&#34;
        return utils.get_dataloaders(self.hyperparameters[&#39;dataloaders&#39;], self.dataset, self.valid_dataset)

    def get_model(self):
        &#34;&#34;&#34;Initialize and get the RetinaNet.

        Returns:
            torch.nn.Module: The RetinaNet model.
        &#34;&#34;&#34;
        hyperparameters = self.hyperparameters[&#39;model&#39;]

        return RetinaNet(
            classes=hyperparameters[&#39;classes&#39;],
            resnet=hyperparameters[&#39;resnet&#39;],
            features=hyperparameters[&#39;features&#39;],
            anchors=hyperparameters[&#39;anchors&#39;],
            pretrained=hyperparameters[&#39;pretrained&#39;]
        )

    def get_criterion(self):
        &#34;&#34;&#34;Initialize and get the FocalLoss.

        Returns:
            torch.nn.Module: The FocalLoss.
        &#34;&#34;&#34;
        hyperparameters = self.hyperparameters[&#39;criterion&#39;]

        return FocalLoss(
            alpha=hyperparameters[&#39;alpha&#39;],
            gamma=hyperparameters[&#39;gamma&#39;],
            iou_thresholds=hyperparameters[&#39;iou_thresholds&#39;],
            increase_foreground_by=hyperparameters[&#39;increase_foreground_by&#39;],
            device=self.device
        )

    def get_optimizer(self):
        &#34;&#34;&#34;Returns the optimizer for the training.

        It has the classic SGD optimizer, but this trainer also
        includes the [AdaBound optimizer](https://github.com/Luolc/AdaBound) that it&#39;s
        supposed to be as fast as Adam and as good as SGD.

        You can provide the optimizer that you want to use in the &#39;optimizer&#39; hyperparameter
        changing the &#39;use&#39; parameter and providing the name of the one that
        you want to use.

        Returns:
            AdaBound: The adabound optimizer for the training.
        &#34;&#34;&#34;
        params = self.hyperparameters[&#39;optimizer&#39;]
        optimizer = params[&#39;use&#39;].lower()

        if optimizer == &#39;adabound&#39;:
            params = params[&#39;adabound&#39;]
            return AdaBound(self.model.parameters(), lr=params[&#39;lr&#39;], final_lr=params[&#39;final_lr&#39;])

        if optimizer == &#39;sgd&#39;:
            params = params[&#39;sgd&#39;]
            return torch.optim.SGD(self.model.parameters(),
                                   lr=params[&#39;lr&#39;],
                                   momentum=params[&#39;momentum&#39;],
                                   weight_decay=params[&#39;weight_decay&#39;])

        raise ValueError(&#39;Cannot find the parameters for the optimizer &#34;{}&#34;&#39;.format(params[&#39;use&#39;]))

    def get_scheduler(self):
        &#34;&#34;&#34;Get the learning rate scheduler.

        Returns:
            torch.optim.lr_scheduler.ReduceLROnPlateau: The learning rate scheduler.
        &#34;&#34;&#34;
        hyperparameters = self.hyperparameters[&#39;scheduler&#39;]
        return ReduceLROnPlateau(
            optimizer=self.optimizer,
            mode=&#39;min&#39;,
            factor=hyperparameters[&#39;factor&#39;],
            patience=hyperparameters[&#39;patience&#39;],
            verbose=True,
            threshold=hyperparameters[&#39;threshold&#39;]
        )

    ####################################
    ###           METHODS            ###
    ####################################

    def forward(self, *args):
        &#34;&#34;&#34;Forward pass through the network and loss computation.

        Returns:
            torch.Tensor: The loss of the batch.
        &#34;&#34;&#34;
        images, annotations, *_ = args
        images, annotations = images.to(self.device), annotations.to(self.device)

        anchors, regressions, classifications = self.model(images)
        del images

        classification_loss, regression_loss = self.criterion(anchors, regressions, classifications, annotations)
        del anchors, regressions, classifications, annotations

        weights = self.hyperparameters[&#39;criterion&#39;][&#39;weights&#39;]
        classification_loss *= weights[&#39;classification&#39;]
        regression_loss *= weights[&#39;regression&#39;]

        loss = classification_loss + regression_loss

        # Log the classification and regression loss too:
        self.current_log[&#39;Class.&#39;] = &#39;{:.5f}&#39;.format(float(classification_loss))
        self.current_log[&#39;Regr.&#39;] = &#39;{:.5f}&#39;.format(float(regression_loss))
        self.current_log[&#39;Pos&#39;] = &#39;{:.4f}&#39;.format(float(self.criterion.pos_loss * weights[&#39;classification&#39;]))
        self.current_log[&#39;Neg&#39;] = &#39;{:.4f}&#39;.format(float(self.criterion.neg_loss * weights[&#39;classification&#39;]))

        return loss

    def backward(self, loss):
        &#34;&#34;&#34;Do the backward pass over the network.

        Arguments:
            loss (torch.Tensor): The loss value computed during the forward pass.
        &#34;&#34;&#34;
        loss.backward()
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.1)

    def eval(self):
        &#34;&#34;&#34;Put the model in evaluation mode.&#34;&#34;&#34;
        params = self.hyperparameters[&#39;model&#39;][&#39;evaluation&#39;]
        self.model.eval(threshold=params[&#39;threshold&#39;], iou_threshold=params[&#39;iou_threshold&#39;], loss=True)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="torchsight.trainers.retinanet.RetinaNetTrainer"><code class="flex name class">
<span>class <span class="ident">RetinaNetTrainer</span></span>
<span>(</span><span><small>ancestors:</small> <a title="torchsight.trainers.trainer.Trainer" href="trainer.html#torchsight.trainers.trainer.Trainer">Trainer</a>)</span>
</code></dt>
<dd>
<section class="desc"><p>RetinaNet trainer class.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class RetinaNetTrainer(Trainer):
    &#34;&#34;&#34;RetinaNet trainer class.&#34;&#34;&#34;
    # Base hyperparameters, can be replaced in the initialization of the trainer:
    # &gt;&gt;&gt; RetinaNetTrainer(hyperparameters={&#39;RetinaNet&#39;: {&#39;classes&#39;: 1}})
    hyperparameters = {
        &#39;model&#39;: {
            &#39;resnet&#39;: 50,
            &#39;features&#39;: {
                &#39;pyramid&#39;: 256,
                &#39;regression&#39;: 256,
                &#39;classification&#39;: 256
            },
            &#39;anchors&#39;: {
                &#39;sizes&#39;: [32, 64, 128, 256, 512],
                &#39;scales&#39;: [2 ** 0, 2 ** (1/3), 2 ** (2/3)],
                &#39;ratios&#39;: [0.5, 1, 2]
            },
            &#39;pretrained&#39;: True,
            &#39;evaluation&#39;: {
                &#39;threshold&#39;: 0.5,
                &#39;iou_threshold&#39;: 0.5
            }
        },
        &#39;criterion&#39;: {
            &#39;alpha&#39;: 0.25,
            &#39;gamma&#39;: 2.0,
            &#39;iou_thresholds&#39;: {
                &#39;background&#39;: 0.4,
                &#39;object&#39;: 0.5
            },
            &#39;increase_foreground_by&#39;: 1e3,
            # Weight of each loss. See train method.
            &#39;weights&#39;: {&#39;classification&#39;: 1e3, &#39;regression&#39;: 1}
        },
        &#39;datasets&#39;: {
            &#39;use&#39;: &#39;coco&#39;,
            &#39;coco&#39;: {
                &#39;root&#39;: &#39;./datasets/coco&#39;,
                &#39;class_names&#39;: (),  # () indicates all classes
                &#39;train&#39;: &#39;train2017&#39;,
                &#39;validation&#39;: &#39;val2017&#39;
            },
            &#39;logo32plus&#39;: {
                &#39;root&#39;: &#39;./datasets/logo32plus&#39;,
                &#39;classes&#39;: None,
            },
            &#39;flickr32&#39;: {
                &#39;root&#39;: &#39;./datasets/flickr32&#39;,
                &#39;brands&#39;: None,
                &#39;only_boxes&#39;: True,
                &#39;training&#39;: &#39;trainval&#39;,  # The name of the dataset to use for training
                &#39;validation&#39;: &#39;test&#39;  # The name of the dataset to use for validation
            }
        },
        &#39;dataloaders&#39;: {
            &#39;batch_size&#39;: 1,
            &#39;shuffle&#39;: True,
            &#39;num_workers&#39;: 1
        },
        &#39;optimizer&#39;: {
            &#39;use&#39;: &#39;sgd&#39;,  # Which optimizer the trainer must use
            &#39;adabound&#39;: {
                &#39;lr&#39;: 1e-3,  # Learning rate
                &#39;final_lr&#39;: 1  # When the optimizer change from Adam to SGD
            },
            &#39;sgd&#39;: {
                &#39;lr&#39;: 1e-2,
                &#39;momentum&#39;: 0.9,
                &#39;weight_decay&#39;: 1e-4
            }
        },
        &#39;scheduler&#39;: {
            &#39;factor&#39;: 0.1,
            &#39;patience&#39;: 5,
            &#39;threshold&#39;: 0.01
        },
        &#39;transform&#39;: {
            &#39;GaussNoise&#39;: {
                &#39;var_limit&#39;: (10, 50),
                &#39;p&#39;: 0.5
            },
            &#39;GaussianBlur&#39;: {
                &#39;blur_limit&#39;: 0.7,
                &#39;p&#39;: 0.5
            },
            &#39;RandomBrightnessContrast&#39;: {
                &#39;brightness_limit&#39;: 0.2,
                &#39;contrast_limit&#39;: 0.2,
                &#39;p&#39;: 0.5
            },
            &#39;Rotate&#39;: {
                &#39;limit&#39;: 45,
                &#39;p&#39;: 0.5
            },
            &#39;LongestMaxSize&#39;: {
                &#39;max_size&#39;: 512
            },
            &#39;PadIfNeeded&#39;: {
                &#39;min_height&#39;: 512,
                &#39;min_width&#39;: 512
            },
            &#39;RandomSizedBBoxSafeCrop&#39;: {
                &#39;height&#39;: 512,
                &#39;width&#39;: 512
            }
        }
    }

    ####################################
    ###           GETTERS            ###
    ####################################

    def get_transform(self):
        &#34;&#34;&#34;Initialize and get the transforms for the images.

        Arguments:
            params (dict): The dict with the params for the transforms.
                It must have &#39;resize&#39; and &#39;normalize&#39; args values.

        Returns:
            torchvision.transform.Compose: The Compose of the transformations.
        &#34;&#34;&#34;
        return AugmentDetection(params=self.hyperparameters[&#39;transform&#39;])

    def get_datasets(self):
        &#34;&#34;&#34;Initialize and get the Coco datasets for training and evaluation.

        Returns:
            tuple: A Tuple with the torch.utils.data.Datasets for training and validation.
        &#34;&#34;&#34;
        transform = self.get_transform()

        params = self.hyperparameters[&#39;datasets&#39;]
        dataset = params[&#39;use&#39;]

        if dataset == &#39;coco&#39;:
            params = params[&#39;coco&#39;]

            n_classes = len(params[&#39;class_names&#39;])
            n_classes = 80 if n_classes == 0 else n_classes
            self.hyperparameters[&#39;model&#39;][&#39;classes&#39;] = n_classes

            return (CocoDataset(root=params[&#39;root&#39;],
                                dataset=params[&#39;train&#39;],
                                classes_names=params[&#39;class_names&#39;],
                                transform=transform),
                    CocoDataset(root=params[&#39;root&#39;],
                                dataset=params[&#39;validation&#39;],
                                classes_names=params[&#39;class_names&#39;],
                                transform=transform))

        if dataset == &#39;logo32plus&#39;:
            params = params[&#39;logo32plus&#39;]
            num_classes = len(params[&#39;classes&#39;]) if params[&#39;classes&#39;] is not None else 32

            self.hyperparameters[&#39;model&#39;][&#39;classes&#39;] = num_classes

            return (Logo32plusDataset(**params, dataset=&#39;training&#39;, transform=transform),
                    Logo32plusDataset(**params, dataset=&#39;validation&#39;, transform=transform))

        if dataset == &#39;flickr32&#39;:
            params = params[&#39;flickr32&#39;]
            num_classes = len(params[&#39;brands&#39;]) if params[&#39;brands&#39;] is not None else 32

            self.hyperparameters[&#39;model&#39;][&#39;classes&#39;] = num_classes

            kwargs = {
                &#39;root&#39;: params[&#39;root&#39;],
                &#39;brands&#39;: params[&#39;brands&#39;],
                &#39;only_boxes&#39;: params[&#39;only_boxes&#39;],
                &#39;transform&#39;: transform
            }

            return (Flickr32Dataset(**kwargs, dataset=params[&#39;training&#39;]),
                    Flickr32Dataset(**kwargs, dataset=params[&#39;validation&#39;]))

    def get_dataloaders(self):
        &#34;&#34;&#34;Initialize and get the dataloaders for the datasets.

        Returns:
            torch.utils.data.Dataloaders: The dataloader for the training dataset.
            torch.utils.data.Dataloaders: The dataloader for the validation dataset.
        &#34;&#34;&#34;
        return utils.get_dataloaders(self.hyperparameters[&#39;dataloaders&#39;], self.dataset, self.valid_dataset)

    def get_model(self):
        &#34;&#34;&#34;Initialize and get the RetinaNet.

        Returns:
            torch.nn.Module: The RetinaNet model.
        &#34;&#34;&#34;
        hyperparameters = self.hyperparameters[&#39;model&#39;]

        return RetinaNet(
            classes=hyperparameters[&#39;classes&#39;],
            resnet=hyperparameters[&#39;resnet&#39;],
            features=hyperparameters[&#39;features&#39;],
            anchors=hyperparameters[&#39;anchors&#39;],
            pretrained=hyperparameters[&#39;pretrained&#39;]
        )

    def get_criterion(self):
        &#34;&#34;&#34;Initialize and get the FocalLoss.

        Returns:
            torch.nn.Module: The FocalLoss.
        &#34;&#34;&#34;
        hyperparameters = self.hyperparameters[&#39;criterion&#39;]

        return FocalLoss(
            alpha=hyperparameters[&#39;alpha&#39;],
            gamma=hyperparameters[&#39;gamma&#39;],
            iou_thresholds=hyperparameters[&#39;iou_thresholds&#39;],
            increase_foreground_by=hyperparameters[&#39;increase_foreground_by&#39;],
            device=self.device
        )

    def get_optimizer(self):
        &#34;&#34;&#34;Returns the optimizer for the training.

        It has the classic SGD optimizer, but this trainer also
        includes the [AdaBound optimizer](https://github.com/Luolc/AdaBound) that it&#39;s
        supposed to be as fast as Adam and as good as SGD.

        You can provide the optimizer that you want to use in the &#39;optimizer&#39; hyperparameter
        changing the &#39;use&#39; parameter and providing the name of the one that
        you want to use.

        Returns:
            AdaBound: The adabound optimizer for the training.
        &#34;&#34;&#34;
        params = self.hyperparameters[&#39;optimizer&#39;]
        optimizer = params[&#39;use&#39;].lower()

        if optimizer == &#39;adabound&#39;:
            params = params[&#39;adabound&#39;]
            return AdaBound(self.model.parameters(), lr=params[&#39;lr&#39;], final_lr=params[&#39;final_lr&#39;])

        if optimizer == &#39;sgd&#39;:
            params = params[&#39;sgd&#39;]
            return torch.optim.SGD(self.model.parameters(),
                                   lr=params[&#39;lr&#39;],
                                   momentum=params[&#39;momentum&#39;],
                                   weight_decay=params[&#39;weight_decay&#39;])

        raise ValueError(&#39;Cannot find the parameters for the optimizer &#34;{}&#34;&#39;.format(params[&#39;use&#39;]))

    def get_scheduler(self):
        &#34;&#34;&#34;Get the learning rate scheduler.

        Returns:
            torch.optim.lr_scheduler.ReduceLROnPlateau: The learning rate scheduler.
        &#34;&#34;&#34;
        hyperparameters = self.hyperparameters[&#39;scheduler&#39;]
        return ReduceLROnPlateau(
            optimizer=self.optimizer,
            mode=&#39;min&#39;,
            factor=hyperparameters[&#39;factor&#39;],
            patience=hyperparameters[&#39;patience&#39;],
            verbose=True,
            threshold=hyperparameters[&#39;threshold&#39;]
        )

    ####################################
    ###           METHODS            ###
    ####################################

    def forward(self, *args):
        &#34;&#34;&#34;Forward pass through the network and loss computation.

        Returns:
            torch.Tensor: The loss of the batch.
        &#34;&#34;&#34;
        images, annotations, *_ = args
        images, annotations = images.to(self.device), annotations.to(self.device)

        anchors, regressions, classifications = self.model(images)
        del images

        classification_loss, regression_loss = self.criterion(anchors, regressions, classifications, annotations)
        del anchors, regressions, classifications, annotations

        weights = self.hyperparameters[&#39;criterion&#39;][&#39;weights&#39;]
        classification_loss *= weights[&#39;classification&#39;]
        regression_loss *= weights[&#39;regression&#39;]

        loss = classification_loss + regression_loss

        # Log the classification and regression loss too:
        self.current_log[&#39;Class.&#39;] = &#39;{:.5f}&#39;.format(float(classification_loss))
        self.current_log[&#39;Regr.&#39;] = &#39;{:.5f}&#39;.format(float(regression_loss))
        self.current_log[&#39;Pos&#39;] = &#39;{:.4f}&#39;.format(float(self.criterion.pos_loss * weights[&#39;classification&#39;]))
        self.current_log[&#39;Neg&#39;] = &#39;{:.4f}&#39;.format(float(self.criterion.neg_loss * weights[&#39;classification&#39;]))

        return loss

    def backward(self, loss):
        &#34;&#34;&#34;Do the backward pass over the network.

        Arguments:
            loss (torch.Tensor): The loss value computed during the forward pass.
        &#34;&#34;&#34;
        loss.backward()
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.1)

    def eval(self):
        &#34;&#34;&#34;Put the model in evaluation mode.&#34;&#34;&#34;
        params = self.hyperparameters[&#39;model&#39;][&#39;evaluation&#39;]
        self.model.eval(threshold=params[&#39;threshold&#39;], iou_threshold=params[&#39;iou_threshold&#39;], loss=True)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="torchsight.trainers.retinanet.RetinaNetTrainer.hyperparameters"><code class="name">var <span class="ident">hyperparameters</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="torchsight.trainers.retinanet.RetinaNetTrainer.backward"><code class="name flex">
<span>def <span class="ident">backward</span></span>(<span>self, loss)</span>
</code></dt>
<dd>
<section class="desc"><p>Do the backward pass over the network.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>loss</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>The loss value computed during the forward pass.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def backward(self, loss):
    &#34;&#34;&#34;Do the backward pass over the network.

    Arguments:
        loss (torch.Tensor): The loss value computed during the forward pass.
    &#34;&#34;&#34;
    loss.backward()
    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.1)</code></pre>
</details>
</dd>
<dt id="torchsight.trainers.retinanet.RetinaNetTrainer.eval"><code class="name flex">
<span>def <span class="ident">eval</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Put the model in evaluation mode.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def eval(self):
    &#34;&#34;&#34;Put the model in evaluation mode.&#34;&#34;&#34;
    params = self.hyperparameters[&#39;model&#39;][&#39;evaluation&#39;]
    self.model.eval(threshold=params[&#39;threshold&#39;], iou_threshold=params[&#39;iou_threshold&#39;], loss=True)</code></pre>
</details>
</dd>
<dt id="torchsight.trainers.retinanet.RetinaNetTrainer.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, *args)</span>
</code></dt>
<dd>
<section class="desc"><p>Forward pass through the network and loss computation.</p>
<h2 id="returns">Returns</h2>
<p>torch.Tensor: The loss of the batch.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def forward(self, *args):
    &#34;&#34;&#34;Forward pass through the network and loss computation.

    Returns:
        torch.Tensor: The loss of the batch.
    &#34;&#34;&#34;
    images, annotations, *_ = args
    images, annotations = images.to(self.device), annotations.to(self.device)

    anchors, regressions, classifications = self.model(images)
    del images

    classification_loss, regression_loss = self.criterion(anchors, regressions, classifications, annotations)
    del anchors, regressions, classifications, annotations

    weights = self.hyperparameters[&#39;criterion&#39;][&#39;weights&#39;]
    classification_loss *= weights[&#39;classification&#39;]
    regression_loss *= weights[&#39;regression&#39;]

    loss = classification_loss + regression_loss

    # Log the classification and regression loss too:
    self.current_log[&#39;Class.&#39;] = &#39;{:.5f}&#39;.format(float(classification_loss))
    self.current_log[&#39;Regr.&#39;] = &#39;{:.5f}&#39;.format(float(regression_loss))
    self.current_log[&#39;Pos&#39;] = &#39;{:.4f}&#39;.format(float(self.criterion.pos_loss * weights[&#39;classification&#39;]))
    self.current_log[&#39;Neg&#39;] = &#39;{:.4f}&#39;.format(float(self.criterion.neg_loss * weights[&#39;classification&#39;]))

    return loss</code></pre>
</details>
</dd>
<dt id="torchsight.trainers.retinanet.RetinaNetTrainer.get_criterion"><code class="name flex">
<span>def <span class="ident">get_criterion</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize and get the FocalLoss.</p>
<h2 id="returns">Returns</h2>
<p>torch.nn.Module: The FocalLoss.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_criterion(self):
    &#34;&#34;&#34;Initialize and get the FocalLoss.

    Returns:
        torch.nn.Module: The FocalLoss.
    &#34;&#34;&#34;
    hyperparameters = self.hyperparameters[&#39;criterion&#39;]

    return FocalLoss(
        alpha=hyperparameters[&#39;alpha&#39;],
        gamma=hyperparameters[&#39;gamma&#39;],
        iou_thresholds=hyperparameters[&#39;iou_thresholds&#39;],
        increase_foreground_by=hyperparameters[&#39;increase_foreground_by&#39;],
        device=self.device
    )</code></pre>
</details>
</dd>
<dt id="torchsight.trainers.retinanet.RetinaNetTrainer.get_dataloaders"><code class="name flex">
<span>def <span class="ident">get_dataloaders</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize and get the dataloaders for the datasets.</p>
<h2 id="returns">Returns</h2>
<p>torch.utils.data.Dataloaders: The dataloader for the training dataset.
torch.utils.data.Dataloaders: The dataloader for the validation dataset.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_dataloaders(self):
    &#34;&#34;&#34;Initialize and get the dataloaders for the datasets.

    Returns:
        torch.utils.data.Dataloaders: The dataloader for the training dataset.
        torch.utils.data.Dataloaders: The dataloader for the validation dataset.
    &#34;&#34;&#34;
    return utils.get_dataloaders(self.hyperparameters[&#39;dataloaders&#39;], self.dataset, self.valid_dataset)</code></pre>
</details>
</dd>
<dt id="torchsight.trainers.retinanet.RetinaNetTrainer.get_datasets"><code class="name flex">
<span>def <span class="ident">get_datasets</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize and get the Coco datasets for training and evaluation.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tuple</code></strong></dt>
<dd>A Tuple with the torch.utils.data.Datasets for training and validation.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_datasets(self):
    &#34;&#34;&#34;Initialize and get the Coco datasets for training and evaluation.

    Returns:
        tuple: A Tuple with the torch.utils.data.Datasets for training and validation.
    &#34;&#34;&#34;
    transform = self.get_transform()

    params = self.hyperparameters[&#39;datasets&#39;]
    dataset = params[&#39;use&#39;]

    if dataset == &#39;coco&#39;:
        params = params[&#39;coco&#39;]

        n_classes = len(params[&#39;class_names&#39;])
        n_classes = 80 if n_classes == 0 else n_classes
        self.hyperparameters[&#39;model&#39;][&#39;classes&#39;] = n_classes

        return (CocoDataset(root=params[&#39;root&#39;],
                            dataset=params[&#39;train&#39;],
                            classes_names=params[&#39;class_names&#39;],
                            transform=transform),
                CocoDataset(root=params[&#39;root&#39;],
                            dataset=params[&#39;validation&#39;],
                            classes_names=params[&#39;class_names&#39;],
                            transform=transform))

    if dataset == &#39;logo32plus&#39;:
        params = params[&#39;logo32plus&#39;]
        num_classes = len(params[&#39;classes&#39;]) if params[&#39;classes&#39;] is not None else 32

        self.hyperparameters[&#39;model&#39;][&#39;classes&#39;] = num_classes

        return (Logo32plusDataset(**params, dataset=&#39;training&#39;, transform=transform),
                Logo32plusDataset(**params, dataset=&#39;validation&#39;, transform=transform))

    if dataset == &#39;flickr32&#39;:
        params = params[&#39;flickr32&#39;]
        num_classes = len(params[&#39;brands&#39;]) if params[&#39;brands&#39;] is not None else 32

        self.hyperparameters[&#39;model&#39;][&#39;classes&#39;] = num_classes

        kwargs = {
            &#39;root&#39;: params[&#39;root&#39;],
            &#39;brands&#39;: params[&#39;brands&#39;],
            &#39;only_boxes&#39;: params[&#39;only_boxes&#39;],
            &#39;transform&#39;: transform
        }

        return (Flickr32Dataset(**kwargs, dataset=params[&#39;training&#39;]),
                Flickr32Dataset(**kwargs, dataset=params[&#39;validation&#39;]))</code></pre>
</details>
</dd>
<dt id="torchsight.trainers.retinanet.RetinaNetTrainer.get_model"><code class="name flex">
<span>def <span class="ident">get_model</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize and get the RetinaNet.</p>
<h2 id="returns">Returns</h2>
<p>torch.nn.Module: The RetinaNet model.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_model(self):
    &#34;&#34;&#34;Initialize and get the RetinaNet.

    Returns:
        torch.nn.Module: The RetinaNet model.
    &#34;&#34;&#34;
    hyperparameters = self.hyperparameters[&#39;model&#39;]

    return RetinaNet(
        classes=hyperparameters[&#39;classes&#39;],
        resnet=hyperparameters[&#39;resnet&#39;],
        features=hyperparameters[&#39;features&#39;],
        anchors=hyperparameters[&#39;anchors&#39;],
        pretrained=hyperparameters[&#39;pretrained&#39;]
    )</code></pre>
</details>
</dd>
<dt id="torchsight.trainers.retinanet.RetinaNetTrainer.get_optimizer"><code class="name flex">
<span>def <span class="ident">get_optimizer</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns the optimizer for the training.</p>
<p>It has the classic SGD optimizer, but this trainer also
includes the <a href="https://github.com/Luolc/AdaBound">AdaBound optimizer</a> that it's
supposed to be as fast as Adam and as good as SGD.</p>
<p>You can provide the optimizer that you want to use in the 'optimizer' hyperparameter
changing the 'use' parameter and providing the name of the one that
you want to use.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>AdaBound</code></strong></dt>
<dd>The adabound optimizer for the training.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_optimizer(self):
    &#34;&#34;&#34;Returns the optimizer for the training.

    It has the classic SGD optimizer, but this trainer also
    includes the [AdaBound optimizer](https://github.com/Luolc/AdaBound) that it&#39;s
    supposed to be as fast as Adam and as good as SGD.

    You can provide the optimizer that you want to use in the &#39;optimizer&#39; hyperparameter
    changing the &#39;use&#39; parameter and providing the name of the one that
    you want to use.

    Returns:
        AdaBound: The adabound optimizer for the training.
    &#34;&#34;&#34;
    params = self.hyperparameters[&#39;optimizer&#39;]
    optimizer = params[&#39;use&#39;].lower()

    if optimizer == &#39;adabound&#39;:
        params = params[&#39;adabound&#39;]
        return AdaBound(self.model.parameters(), lr=params[&#39;lr&#39;], final_lr=params[&#39;final_lr&#39;])

    if optimizer == &#39;sgd&#39;:
        params = params[&#39;sgd&#39;]
        return torch.optim.SGD(self.model.parameters(),
                               lr=params[&#39;lr&#39;],
                               momentum=params[&#39;momentum&#39;],
                               weight_decay=params[&#39;weight_decay&#39;])

    raise ValueError(&#39;Cannot find the parameters for the optimizer &#34;{}&#34;&#39;.format(params[&#39;use&#39;]))</code></pre>
</details>
</dd>
<dt id="torchsight.trainers.retinanet.RetinaNetTrainer.get_scheduler"><code class="name flex">
<span>def <span class="ident">get_scheduler</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the learning rate scheduler.</p>
<h2 id="returns">Returns</h2>
<p>torch.optim.lr_scheduler.ReduceLROnPlateau: The learning rate scheduler.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_scheduler(self):
    &#34;&#34;&#34;Get the learning rate scheduler.

    Returns:
        torch.optim.lr_scheduler.ReduceLROnPlateau: The learning rate scheduler.
    &#34;&#34;&#34;
    hyperparameters = self.hyperparameters[&#39;scheduler&#39;]
    return ReduceLROnPlateau(
        optimizer=self.optimizer,
        mode=&#39;min&#39;,
        factor=hyperparameters[&#39;factor&#39;],
        patience=hyperparameters[&#39;patience&#39;],
        verbose=True,
        threshold=hyperparameters[&#39;threshold&#39;]
    )</code></pre>
</details>
</dd>
<dt id="torchsight.trainers.retinanet.RetinaNetTrainer.get_transform"><code class="name flex">
<span>def <span class="ident">get_transform</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize and get the transforms for the images.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>params</code></strong> :&ensp;<code>dict</code></dt>
<dd>The dict with the params for the transforms.
It must have 'resize' and 'normalize' args values.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>torchvision.transform.Compose: The Compose of the transformations.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_transform(self):
    &#34;&#34;&#34;Initialize and get the transforms for the images.

    Arguments:
        params (dict): The dict with the params for the transforms.
            It must have &#39;resize&#39; and &#39;normalize&#39; args values.

    Returns:
        torchvision.transform.Compose: The Compose of the transformations.
    &#34;&#34;&#34;
    return AugmentDetection(params=self.hyperparameters[&#39;transform&#39;])</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="torchsight.trainers.trainer.Trainer" href="trainer.html#torchsight.trainers.trainer.Trainer">Trainer</a></b></code>:
<ul class="hlist">
<li><code><a title="torchsight.trainers.trainer.Trainer.__init__" href="trainer.html#torchsight.trainers.trainer.Trainer.__init__">__init__</a></code></li>
<li><code><a title="torchsight.trainers.trainer.Trainer.batch_callback" href="trainer.html#torchsight.trainers.trainer.Trainer.batch_callback">batch_callback</a></code></li>
<li><code><a title="torchsight.trainers.trainer.Trainer.epoch_callback" href="trainer.html#torchsight.trainers.trainer.Trainer.epoch_callback">epoch_callback</a></code></li>
<li><code><a title="torchsight.trainers.trainer.Trainer.from_checkpoint" href="trainer.html#torchsight.trainers.trainer.Trainer.from_checkpoint">from_checkpoint</a></code></li>
<li><code><a title="torchsight.trainers.trainer.Trainer.get_checkpoint_name" href="trainer.html#torchsight.trainers.trainer.Trainer.get_checkpoint_name">get_checkpoint_name</a></code></li>
<li><code><a title="torchsight.trainers.trainer.Trainer.get_logger" href="trainer.html#torchsight.trainers.trainer.Trainer.get_logger">get_logger</a></code></li>
<li><code><a title="torchsight.trainers.trainer.Trainer.resume" href="trainer.html#torchsight.trainers.trainer.Trainer.resume">resume</a></code></li>
<li><code><a title="torchsight.trainers.trainer.Trainer.save" href="trainer.html#torchsight.trainers.trainer.Trainer.save">save</a></code></li>
<li><code><a title="torchsight.trainers.trainer.Trainer.train" href="trainer.html#torchsight.trainers.trainer.Trainer.train">train</a></code></li>
<li><code><a title="torchsight.trainers.trainer.Trainer.validate" href="trainer.html#torchsight.trainers.trainer.Trainer.validate">validate</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="torchsight.trainers" href="index.html">torchsight.trainers</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer" href="#torchsight.trainers.retinanet.RetinaNetTrainer">RetinaNetTrainer</a></code></h4>
<ul class="two-column">
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.backward" href="#torchsight.trainers.retinanet.RetinaNetTrainer.backward">backward</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.eval" href="#torchsight.trainers.retinanet.RetinaNetTrainer.eval">eval</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.forward" href="#torchsight.trainers.retinanet.RetinaNetTrainer.forward">forward</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.get_criterion" href="#torchsight.trainers.retinanet.RetinaNetTrainer.get_criterion">get_criterion</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.get_dataloaders" href="#torchsight.trainers.retinanet.RetinaNetTrainer.get_dataloaders">get_dataloaders</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.get_datasets" href="#torchsight.trainers.retinanet.RetinaNetTrainer.get_datasets">get_datasets</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.get_model" href="#torchsight.trainers.retinanet.RetinaNetTrainer.get_model">get_model</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.get_optimizer" href="#torchsight.trainers.retinanet.RetinaNetTrainer.get_optimizer">get_optimizer</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.get_scheduler" href="#torchsight.trainers.retinanet.RetinaNetTrainer.get_scheduler">get_scheduler</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.get_transform" href="#torchsight.trainers.retinanet.RetinaNetTrainer.get_transform">get_transform</a></code></li>
<li><code><a title="torchsight.trainers.retinanet.RetinaNetTrainer.hyperparameters" href="#torchsight.trainers.retinanet.RetinaNetTrainer.hyperparameters">hyperparameters</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.5.4</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>