<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.5.4" />
<title>torchsight.retrievers.faiss API documentation</title>
<meta name="description" content="Retrievers using FAISS as database." />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.name small{font-weight:normal}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase;cursor:pointer}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title"><code>torchsight.retrievers.faiss</code> module</h1>
</header>
<section id="section-intro">
<p>Retrievers using FAISS as database.</p>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">&#34;&#34;&#34;Retrievers using FAISS as database.&#34;&#34;&#34;
import os
import time

import faiss
import torch

from .retriever import InstanceRetriever


class FaissInstanceRetriever(InstanceRetriever):
    &#34;&#34;&#34;A retriver that looks for instance of objects in a database of images.

    You must provide a model in the `get_model()` method.

    You can call the `create_database()` method to create the database,
    and then query instances of objects using the `query()` method.
    &#34;&#34;&#34;

    def __init__(self, *args, storage=&#39;./databases&#39;, index=&#39;IndexFlatIP&#39;, **kwargs):
        &#34;&#34;&#34;Initialize the retriever.

        Arguments:
            storage (str, optional): The path to the directory where to store the data.
            index (str, optional): The index of FAISS to use to store the embeddings.
                The default one is the FlatIP (Inner Product) that performs the cosine distance
                so your embeddings must be normalized beforehand.
                You can find more indexes here:
                https://github.com/facebookresearch/faiss/wiki/Faiss-indexes

            The rest of the parameters are the same as InstanceRetriever.
        &#34;&#34;&#34;
        self.database = None
        self.storage = storage
        self.embeddings_file = os.path.join(self.storage, &#39;embeddings.index&#39;)
        self.boxes_file = os.path.join(self.storage, &#39;boxes.index&#39;)
        self.index = index
        self.embeddings = None  # FAISS index for the embeddings
        self.boxes = None  # FAISS index for the boxes
        self.paths = {}  # A dict to map between FAISS ids and images&#39; paths

    ##############################
    ###        SETTERS        ####
    ##############################

    def _set_indexes(self, dim):
        &#34;&#34;&#34;Set the FAISS index.

        The embedding could have any size but the bounding boxes must have size 4.

        Arguments:
            dim (int): The dimension of the embeddings.
        &#34;&#34;&#34;
        if self.index == &#39;IndexFlatL2&#39;:
            self.embeddings = faiss.IndexFlatL2(dim)
            self.boxes = faiss.IndexFlatL2(4)
        elif self.index == &#39;IndexFlatIP&#39;:
            self.embeddings = faiss.IndexFlatIP(dim)
            self.boxes = faiss.IndexFlatIP(4)
        else:
            raise ValueError(&#39;Index &#34;{}&#34; not supported.&#39;.format(self.index))

    ######################################
    ###       DATABASE METHODS         ###
    ######################################

    def create_database(self, batch_size=8, num_workers=8):
        &#34;&#34;&#34;Generates the database to insert in an index of FAISS.

        Arguments:
            batch_size (int): The batch size to use to compute in parallel the images.
            num_workers (int): The number of process to use to load the images and generate
                the batches.
        &#34;&#34;&#34;
        self.print(&#39;Creating database ...&#39;)

        dataloader = self.dataset.get_dataloader(batch_size, num_workers)

        num_batches = len(dataloader)
        total_embs = 0
        total_imgs = 0
        init = time.time()

        with torch.no_grad():
            for i, (images, paths) in enumerate(dataloader):
                embeddings, boxes = self.model(images)

                # Create the indexes if they are not created yet
                if self.embeddings is None or self.boxes is None:
                    self._set_indexes(embeddings.shape[1])

                # Add the vectors to the indexes
                self.embeddings.add(embeddings)
                self.boxes.add(boxes)

                # Map the id of the vectors to their image path
                for j, path in paths:
                    self.paths[(i*batch_size) + j] = path

                # Show some stats about the progress
                total_imgs += images.shape[0]
                total_embs += embeddings.shape[0]
                self.logger.log({
                    &#39;Batch&#39;: &#39;{}/{}&#39;.format(i + 1, num_batches),
                    &#39;Time&#39;: &#39;{:.3f} s&#39;.format(time.time() - init),
                    &#39;Images&#39;: total_imgs,
                    &#39;Embeddings&#39;: total_embs,
                })

        self.save()

    def query(self, images, boxes=None, strategy=&#39;max_iou&#39;, k=100):
        &#34;&#34;&#34;TODO:&#34;&#34;&#34;
        raise NotImplementedError()

    ###################################
    ###        SAVING/LOADING       ###
    ###################################

    def save(self):
        &#34;&#34;&#34;Save the indexes in the storage directory.&#34;&#34;&#34;
        self.print(&#39;Saving indexes ...&#39;)
        faiss.write_index(self.embeddings, self.embeddings_file)
        faiss.write_index(self.boxes, self.boxes_file)

    def load(self):
        &#34;&#34;&#34;Load the indexes from the storage directory.&#34;&#34;&#34;
        self.print(&#39;Loading indexes ...&#39;)

        if not os.path.exists(self.embeddings_file):
            raise ValueError(&#39;There is no &#39;)

        self.embeddings = faiss.read_index(self.embeddings_file)
        self.boxes = faiss.read_index(self.boxes_file)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="torchsight.retrievers.faiss.FaissInstanceRetriever"><code class="flex name class">
<span>class <span class="ident">FaissInstanceRetriever</span></span>
<span>(</span><span><small>ancestors:</small> <a title="torchsight.retrievers.retriever.InstanceRetriever" href="retriever.html#torchsight.retrievers.retriever.InstanceRetriever">InstanceRetriever</a>, <a title="torchsight.utils.print.PrintMixin" href="../utils/print.html#torchsight.utils.print.PrintMixin">PrintMixin</a>)</span>
</code></dt>
<dd>
<section class="desc"><p>A retriver that looks for instance of objects in a database of images.</p>
<p>You must provide a model in the <code>get_model()</code> method.</p>
<p>You can call the <code>create_database()</code> method to create the database,
and then query instances of objects using the <code>query()</code> method.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class FaissInstanceRetriever(InstanceRetriever):
    &#34;&#34;&#34;A retriver that looks for instance of objects in a database of images.

    You must provide a model in the `get_model()` method.

    You can call the `create_database()` method to create the database,
    and then query instances of objects using the `query()` method.
    &#34;&#34;&#34;

    def __init__(self, *args, storage=&#39;./databases&#39;, index=&#39;IndexFlatIP&#39;, **kwargs):
        &#34;&#34;&#34;Initialize the retriever.

        Arguments:
            storage (str, optional): The path to the directory where to store the data.
            index (str, optional): The index of FAISS to use to store the embeddings.
                The default one is the FlatIP (Inner Product) that performs the cosine distance
                so your embeddings must be normalized beforehand.
                You can find more indexes here:
                https://github.com/facebookresearch/faiss/wiki/Faiss-indexes

            The rest of the parameters are the same as InstanceRetriever.
        &#34;&#34;&#34;
        self.database = None
        self.storage = storage
        self.embeddings_file = os.path.join(self.storage, &#39;embeddings.index&#39;)
        self.boxes_file = os.path.join(self.storage, &#39;boxes.index&#39;)
        self.index = index
        self.embeddings = None  # FAISS index for the embeddings
        self.boxes = None  # FAISS index for the boxes
        self.paths = {}  # A dict to map between FAISS ids and images&#39; paths

    ##############################
    ###        SETTERS        ####
    ##############################

    def _set_indexes(self, dim):
        &#34;&#34;&#34;Set the FAISS index.

        The embedding could have any size but the bounding boxes must have size 4.

        Arguments:
            dim (int): The dimension of the embeddings.
        &#34;&#34;&#34;
        if self.index == &#39;IndexFlatL2&#39;:
            self.embeddings = faiss.IndexFlatL2(dim)
            self.boxes = faiss.IndexFlatL2(4)
        elif self.index == &#39;IndexFlatIP&#39;:
            self.embeddings = faiss.IndexFlatIP(dim)
            self.boxes = faiss.IndexFlatIP(4)
        else:
            raise ValueError(&#39;Index &#34;{}&#34; not supported.&#39;.format(self.index))

    ######################################
    ###       DATABASE METHODS         ###
    ######################################

    def create_database(self, batch_size=8, num_workers=8):
        &#34;&#34;&#34;Generates the database to insert in an index of FAISS.

        Arguments:
            batch_size (int): The batch size to use to compute in parallel the images.
            num_workers (int): The number of process to use to load the images and generate
                the batches.
        &#34;&#34;&#34;
        self.print(&#39;Creating database ...&#39;)

        dataloader = self.dataset.get_dataloader(batch_size, num_workers)

        num_batches = len(dataloader)
        total_embs = 0
        total_imgs = 0
        init = time.time()

        with torch.no_grad():
            for i, (images, paths) in enumerate(dataloader):
                embeddings, boxes = self.model(images)

                # Create the indexes if they are not created yet
                if self.embeddings is None or self.boxes is None:
                    self._set_indexes(embeddings.shape[1])

                # Add the vectors to the indexes
                self.embeddings.add(embeddings)
                self.boxes.add(boxes)

                # Map the id of the vectors to their image path
                for j, path in paths:
                    self.paths[(i*batch_size) + j] = path

                # Show some stats about the progress
                total_imgs += images.shape[0]
                total_embs += embeddings.shape[0]
                self.logger.log({
                    &#39;Batch&#39;: &#39;{}/{}&#39;.format(i + 1, num_batches),
                    &#39;Time&#39;: &#39;{:.3f} s&#39;.format(time.time() - init),
                    &#39;Images&#39;: total_imgs,
                    &#39;Embeddings&#39;: total_embs,
                })

        self.save()

    def query(self, images, boxes=None, strategy=&#39;max_iou&#39;, k=100):
        &#34;&#34;&#34;TODO:&#34;&#34;&#34;
        raise NotImplementedError()

    ###################################
    ###        SAVING/LOADING       ###
    ###################################

    def save(self):
        &#34;&#34;&#34;Save the indexes in the storage directory.&#34;&#34;&#34;
        self.print(&#39;Saving indexes ...&#39;)
        faiss.write_index(self.embeddings, self.embeddings_file)
        faiss.write_index(self.boxes, self.boxes_file)

    def load(self):
        &#34;&#34;&#34;Load the indexes from the storage directory.&#34;&#34;&#34;
        self.print(&#39;Loading indexes ...&#39;)

        if not os.path.exists(self.embeddings_file):
            raise ValueError(&#39;There is no &#39;)

        self.embeddings = faiss.read_index(self.embeddings_file)
        self.boxes = faiss.read_index(self.boxes_file)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="torchsight.retrievers.faiss.FaissInstanceRetriever.__init__"><code class="name flex">
<span>def <span class="ident">__init__</span></span>(<span>self, *args, storage=&#39;./databases&#39;, index=&#39;IndexFlatIP&#39;, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize the retriever.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>storage</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The path to the directory where to store the data.</dd>
<dt><strong><code>index</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The index of FAISS to use to store the embeddings.
The default one is the FlatIP (Inner Product) that performs the cosine distance
so your embeddings must be normalized beforehand.
You can find more indexes here:
<a href="https://github.com/facebookresearch/faiss/wiki/Faiss-indexes">https://github.com/facebookresearch/faiss/wiki/Faiss-indexes</a></dd>
</dl>
<p>The rest of the parameters are the same as InstanceRetriever.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def __init__(self, *args, storage=&#39;./databases&#39;, index=&#39;IndexFlatIP&#39;, **kwargs):
    &#34;&#34;&#34;Initialize the retriever.

    Arguments:
        storage (str, optional): The path to the directory where to store the data.
        index (str, optional): The index of FAISS to use to store the embeddings.
            The default one is the FlatIP (Inner Product) that performs the cosine distance
            so your embeddings must be normalized beforehand.
            You can find more indexes here:
            https://github.com/facebookresearch/faiss/wiki/Faiss-indexes

        The rest of the parameters are the same as InstanceRetriever.
    &#34;&#34;&#34;
    self.database = None
    self.storage = storage
    self.embeddings_file = os.path.join(self.storage, &#39;embeddings.index&#39;)
    self.boxes_file = os.path.join(self.storage, &#39;boxes.index&#39;)
    self.index = index
    self.embeddings = None  # FAISS index for the embeddings
    self.boxes = None  # FAISS index for the boxes
    self.paths = {}  # A dict to map between FAISS ids and images&#39; paths</code></pre>
</details>
</dd>
<dt id="torchsight.retrievers.faiss.FaissInstanceRetriever.create_database"><code class="name flex">
<span>def <span class="ident">create_database</span></span>(<span>self, batch_size=8, num_workers=8)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates the database to insert in an index of FAISS.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>batch_size</code></strong> :&ensp;<code>int</code></dt>
<dd>The batch size to use to compute in parallel the images.</dd>
<dt><strong><code>num_workers</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of process to use to load the images and generate
the batches.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def create_database(self, batch_size=8, num_workers=8):
    &#34;&#34;&#34;Generates the database to insert in an index of FAISS.

    Arguments:
        batch_size (int): The batch size to use to compute in parallel the images.
        num_workers (int): The number of process to use to load the images and generate
            the batches.
    &#34;&#34;&#34;
    self.print(&#39;Creating database ...&#39;)

    dataloader = self.dataset.get_dataloader(batch_size, num_workers)

    num_batches = len(dataloader)
    total_embs = 0
    total_imgs = 0
    init = time.time()

    with torch.no_grad():
        for i, (images, paths) in enumerate(dataloader):
            embeddings, boxes = self.model(images)

            # Create the indexes if they are not created yet
            if self.embeddings is None or self.boxes is None:
                self._set_indexes(embeddings.shape[1])

            # Add the vectors to the indexes
            self.embeddings.add(embeddings)
            self.boxes.add(boxes)

            # Map the id of the vectors to their image path
            for j, path in paths:
                self.paths[(i*batch_size) + j] = path

            # Show some stats about the progress
            total_imgs += images.shape[0]
            total_embs += embeddings.shape[0]
            self.logger.log({
                &#39;Batch&#39;: &#39;{}/{}&#39;.format(i + 1, num_batches),
                &#39;Time&#39;: &#39;{:.3f} s&#39;.format(time.time() - init),
                &#39;Images&#39;: total_imgs,
                &#39;Embeddings&#39;: total_embs,
            })

    self.save()</code></pre>
</details>
</dd>
<dt id="torchsight.retrievers.faiss.FaissInstanceRetriever.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Load the indexes from the storage directory.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def load(self):
    &#34;&#34;&#34;Load the indexes from the storage directory.&#34;&#34;&#34;
    self.print(&#39;Loading indexes ...&#39;)

    if not os.path.exists(self.embeddings_file):
        raise ValueError(&#39;There is no &#39;)

    self.embeddings = faiss.read_index(self.embeddings_file)
    self.boxes = faiss.read_index(self.boxes_file)</code></pre>
</details>
</dd>
<dt id="torchsight.retrievers.faiss.FaissInstanceRetriever.query"><code class="name flex">
<span>def <span class="ident">query</span></span>(<span>self, images, boxes=None, strategy=&#39;max_iou&#39;, k=100)</span>
</code></dt>
<dd>
<section class="desc"><p>TODO:</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def query(self, images, boxes=None, strategy=&#39;max_iou&#39;, k=100):
    &#34;&#34;&#34;TODO:&#34;&#34;&#34;
    raise NotImplementedError()</code></pre>
</details>
</dd>
<dt id="torchsight.retrievers.faiss.FaissInstanceRetriever.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Save the indexes in the storage directory.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def save(self):
    &#34;&#34;&#34;Save the indexes in the storage directory.&#34;&#34;&#34;
    self.print(&#39;Saving indexes ...&#39;)
    faiss.write_index(self.embeddings, self.embeddings_file)
    faiss.write_index(self.boxes, self.boxes_file)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="torchsight.retrievers.retriever.InstanceRetriever" href="retriever.html#torchsight.retrievers.retriever.InstanceRetriever">InstanceRetriever</a></b></code>:
<ul class="hlist">
<li><code><a title="torchsight.retrievers.retriever.InstanceRetriever.print" href="../utils/print.html#torchsight.utils.print.PrintMixin.print">print</a></code></li>
<li><code><a title="torchsight.retrievers.retriever.InstanceRetriever.visualize" href="retriever.html#torchsight.retrievers.retriever.InstanceRetriever.visualize">visualize</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="torchsight.retrievers" href="index.html">torchsight.retrievers</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="torchsight.retrievers.faiss.FaissInstanceRetriever" href="#torchsight.retrievers.faiss.FaissInstanceRetriever">FaissInstanceRetriever</a></code></h4>
<ul class="">
<li><code><a title="torchsight.retrievers.faiss.FaissInstanceRetriever.__init__" href="#torchsight.retrievers.faiss.FaissInstanceRetriever.__init__">__init__</a></code></li>
<li><code><a title="torchsight.retrievers.faiss.FaissInstanceRetriever.create_database" href="#torchsight.retrievers.faiss.FaissInstanceRetriever.create_database">create_database</a></code></li>
<li><code><a title="torchsight.retrievers.faiss.FaissInstanceRetriever.load" href="#torchsight.retrievers.faiss.FaissInstanceRetriever.load">load</a></code></li>
<li><code><a title="torchsight.retrievers.faiss.FaissInstanceRetriever.query" href="#torchsight.retrievers.faiss.FaissInstanceRetriever.query">query</a></code></li>
<li><code><a title="torchsight.retrievers.faiss.FaissInstanceRetriever.save" href="#torchsight.retrievers.faiss.FaissInstanceRetriever.save">save</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.5.4</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>