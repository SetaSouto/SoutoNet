<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.5.3" />
<title>torchsight.loggers.json API documentation</title>
<meta name="description" content="JSON Logger module." />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.name small{font-weight:normal}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase;cursor:pointer}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title"><code>torchsight.loggers.json</code> module</h1>
</header>
<section id="section-intro">
<p>JSON Logger module.</p>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">&#34;&#34;&#34;JSON Logger module.&#34;&#34;&#34;
import json
import os

import torch

from .abstract import AbstractLogger


class JSONLogger(AbstractLogger):
    &#34;&#34;&#34;JSON Logger class to save logs in a json format.&#34;&#34;&#34;

    def __init__(self, description=None, directory=&#39;./logs&#39;, filename=&#39;logs.json&#39;):
        &#34;&#34;&#34;Initialize the logger and create the directory that will contain the logs.

        Arguments:
            description (str): Description of the model / training or whatever you want to
                save as free text. It saves this string inside the directory with the filename
                &#39;description.txt&#39;.
            dir (str): Path to the directory that will contain the different log files.
        &#34;&#34;&#34;
        if not os.path.exists(directory):
            os.makedirs(directory)

        self.directory = directory
        self.log_file = os.path.join(self.directory, filename)

        if description is not None:
            with open(os.path.join(self.directory, &#39;description.txt&#39;), &#39;w&#39;) as file:
                file.write(description)

    def log(self, data):
        &#34;&#34;&#34;Log the data.

        Arguments:
            data (dict): A dict with the data to log.
        &#34;&#34;&#34;
        self._print(data)
        self._append(data)

    def _print(self, data):
        &#34;&#34;&#34;Print the data dict in the console.

        It renders a line as [&lt;key&gt; &lt;value&gt;] [ ... ].

        Example:
        A dict like data = {&#39;Batch&#39;: 5, &#39;loss&#39;: 0.874} will render:
        [Batch 5] [loss 0.874]

        Arguments:
            data (dict): The data to log.
        &#34;&#34;&#34;
        log = [&#39;[{} {}]&#39;.format(key, value) for key, value in data.items()]
        print(&#39; &#39;.join(log))

    def _append(self, data):
        &#34;&#34;&#34;Append the values of the data dict to the log file.

        Example:
        For a data dict like {&#39;Batch&#39;: 1, &#39;loss&#39;: 0.4353} it will generate a file like:
        {
            &#39;Batch&#39;: [1],
            &#39;loss&#39;: [0.4353]
        }
        And all the next logs will append the values to its correspondent key, resulting in
        something like:
        {
            &#39;Batch&#39;: [1, 2, 3],
            &#39;loss&#39;: [0.4352, 0.34223, 0.24323]
        }

        Arguments:
            data (dict): The dict with the data to append to the log file.
        &#34;&#34;&#34;
        logs = self.read()

        for key, value in data.items():
            if not key in logs:
                logs[key] = []
            logs[key].append(value)

        with open(self.log_file, &#39;w&#39;) as file:
            file.write(json.dumps(logs))

    def read(self):
        &#34;&#34;&#34;Read the logs from the file (if exists) and return the dict.
        If there is no file it returns an empty dict.

        Returns:
            dict: The json saved with the logs.
        &#34;&#34;&#34;
        if os.path.exists(self.log_file):
            with open(self.log_file, &#39;r&#39;) as file:
                return json.loads(file.read())
        return {}

    def average_loss(self, key=&#39;loss&#39;, window=1e3):
        &#34;&#34;&#34;Average the loss with the given window size and show it.

        Basically it gets the loss from the log file with the given key, average the values for each
        window consecutive times and returns the reduced array.
        For example, if we have 1e5 values for the loss and a window size of 1e3 it average each 1e3
        losses and return an array with 1e2 values.

        If the loss array does not have a multiply of the window size it cuts the oldest values.

        Return:
            torch.Tensor: The tensor with the averaged loss with the given window size.
        &#34;&#34;&#34;
        losses = torch.Tensor([float(val) for val in self.read()[key]])

        n_losses = losses.shape[0]
        if n_losses % window != 0:
            losses = losses[int(n_losses % window):]

        losses = losses.view(-1, window)
        return losses.mean(dim=1)

    def epoch_losses(self, epoch_key=&#39;epoch&#39;, loss_key=&#39;loss&#39;):
        &#34;&#34;&#34;Get the average loss per each epoch.

        Arguments:
            epoch_key (str): The key in the logs dictionary to get the epochs array.
            loss_key (str): The key in the logs dictionary to get the losses array.

        Returns:
            torch.Tensor: The Tensor with the average loss per each epoch.
        &#34;&#34;&#34;
        logs = self.read()
        epochs = logs[epoch_key]
        losses = logs[loss_key]
        # Create a dict with the epoch as the key and inside a dict with &#39;sum&#39; and &#39;count&#39;
        epochs_losses = {}
        # Iterate over the logs
        for index, loss in enumerate(losses):
            epoch = epochs[index]
            if epoch not in epochs_losses:
                epochs_losses[epoch] = {&#39;sum&#39;: 0, &#39;total&#39;: 0}
            epochs_losses[epoch][&#39;sum&#39;] += float(loss)
            epochs_losses[epoch][&#39;total&#39;] += 1

        return torch.Tensor([epochs_losses[epoch][&#39;sum&#39;] / epochs_losses[epoch][&#39;total&#39;] for epoch in epochs_losses])

    def get_epochs(self, epoch_key=&#39;epoch&#39;):
        &#34;&#34;&#34;Return the unique array of epochs.

        Arguments:
            epoch_key (str): The key of the epochs in the logs dict.

        Returns:
            list: The unique list of the epochs number.
        &#34;&#34;&#34;
        return list(set(self.read()[epoch_key]))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="torchsight.loggers.json.JSONLogger"><code class="flex name class">
<span>class <span class="ident">JSONLogger</span></span>
<span>(</span><span><small>ancestors:</small> <a title="torchsight.loggers.abstract.AbstractLogger" href="abstract.html#torchsight.loggers.abstract.AbstractLogger">AbstractLogger</a>)</span>
</code></dt>
<dd>
<section class="desc"><p>JSON Logger class to save logs in a json format.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class JSONLogger(AbstractLogger):
    &#34;&#34;&#34;JSON Logger class to save logs in a json format.&#34;&#34;&#34;

    def __init__(self, description=None, directory=&#39;./logs&#39;, filename=&#39;logs.json&#39;):
        &#34;&#34;&#34;Initialize the logger and create the directory that will contain the logs.

        Arguments:
            description (str): Description of the model / training or whatever you want to
                save as free text. It saves this string inside the directory with the filename
                &#39;description.txt&#39;.
            dir (str): Path to the directory that will contain the different log files.
        &#34;&#34;&#34;
        if not os.path.exists(directory):
            os.makedirs(directory)

        self.directory = directory
        self.log_file = os.path.join(self.directory, filename)

        if description is not None:
            with open(os.path.join(self.directory, &#39;description.txt&#39;), &#39;w&#39;) as file:
                file.write(description)

    def log(self, data):
        &#34;&#34;&#34;Log the data.

        Arguments:
            data (dict): A dict with the data to log.
        &#34;&#34;&#34;
        self._print(data)
        self._append(data)

    def _print(self, data):
        &#34;&#34;&#34;Print the data dict in the console.

        It renders a line as [&lt;key&gt; &lt;value&gt;] [ ... ].

        Example:
        A dict like data = {&#39;Batch&#39;: 5, &#39;loss&#39;: 0.874} will render:
        [Batch 5] [loss 0.874]

        Arguments:
            data (dict): The data to log.
        &#34;&#34;&#34;
        log = [&#39;[{} {}]&#39;.format(key, value) for key, value in data.items()]
        print(&#39; &#39;.join(log))

    def _append(self, data):
        &#34;&#34;&#34;Append the values of the data dict to the log file.

        Example:
        For a data dict like {&#39;Batch&#39;: 1, &#39;loss&#39;: 0.4353} it will generate a file like:
        {
            &#39;Batch&#39;: [1],
            &#39;loss&#39;: [0.4353]
        }
        And all the next logs will append the values to its correspondent key, resulting in
        something like:
        {
            &#39;Batch&#39;: [1, 2, 3],
            &#39;loss&#39;: [0.4352, 0.34223, 0.24323]
        }

        Arguments:
            data (dict): The dict with the data to append to the log file.
        &#34;&#34;&#34;
        logs = self.read()

        for key, value in data.items():
            if not key in logs:
                logs[key] = []
            logs[key].append(value)

        with open(self.log_file, &#39;w&#39;) as file:
            file.write(json.dumps(logs))

    def read(self):
        &#34;&#34;&#34;Read the logs from the file (if exists) and return the dict.
        If there is no file it returns an empty dict.

        Returns:
            dict: The json saved with the logs.
        &#34;&#34;&#34;
        if os.path.exists(self.log_file):
            with open(self.log_file, &#39;r&#39;) as file:
                return json.loads(file.read())
        return {}

    def average_loss(self, key=&#39;loss&#39;, window=1e3):
        &#34;&#34;&#34;Average the loss with the given window size and show it.

        Basically it gets the loss from the log file with the given key, average the values for each
        window consecutive times and returns the reduced array.
        For example, if we have 1e5 values for the loss and a window size of 1e3 it average each 1e3
        losses and return an array with 1e2 values.

        If the loss array does not have a multiply of the window size it cuts the oldest values.

        Return:
            torch.Tensor: The tensor with the averaged loss with the given window size.
        &#34;&#34;&#34;
        losses = torch.Tensor([float(val) for val in self.read()[key]])

        n_losses = losses.shape[0]
        if n_losses % window != 0:
            losses = losses[int(n_losses % window):]

        losses = losses.view(-1, window)
        return losses.mean(dim=1)

    def epoch_losses(self, epoch_key=&#39;epoch&#39;, loss_key=&#39;loss&#39;):
        &#34;&#34;&#34;Get the average loss per each epoch.

        Arguments:
            epoch_key (str): The key in the logs dictionary to get the epochs array.
            loss_key (str): The key in the logs dictionary to get the losses array.

        Returns:
            torch.Tensor: The Tensor with the average loss per each epoch.
        &#34;&#34;&#34;
        logs = self.read()
        epochs = logs[epoch_key]
        losses = logs[loss_key]
        # Create a dict with the epoch as the key and inside a dict with &#39;sum&#39; and &#39;count&#39;
        epochs_losses = {}
        # Iterate over the logs
        for index, loss in enumerate(losses):
            epoch = epochs[index]
            if epoch not in epochs_losses:
                epochs_losses[epoch] = {&#39;sum&#39;: 0, &#39;total&#39;: 0}
            epochs_losses[epoch][&#39;sum&#39;] += float(loss)
            epochs_losses[epoch][&#39;total&#39;] += 1

        return torch.Tensor([epochs_losses[epoch][&#39;sum&#39;] / epochs_losses[epoch][&#39;total&#39;] for epoch in epochs_losses])

    def get_epochs(self, epoch_key=&#39;epoch&#39;):
        &#34;&#34;&#34;Return the unique array of epochs.

        Arguments:
            epoch_key (str): The key of the epochs in the logs dict.

        Returns:
            list: The unique list of the epochs number.
        &#34;&#34;&#34;
        return list(set(self.read()[epoch_key]))</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="torchsight.loggers.json.JSONLogger.__init__"><code class="name flex">
<span>def <span class="ident">__init__</span></span>(<span>self, description=None, directory=&#39;./logs&#39;, filename=&#39;logs.json&#39;)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize the logger and create the directory that will contain the logs.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>description</code></strong> :&ensp;<code>str</code></dt>
<dd>Description of the model / training or whatever you want to
save as free text. It saves this string inside the directory with the filename
'description.txt'.</dd>
<dt><strong><code>dir</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the directory that will contain the different log files.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def __init__(self, description=None, directory=&#39;./logs&#39;, filename=&#39;logs.json&#39;):
    &#34;&#34;&#34;Initialize the logger and create the directory that will contain the logs.

    Arguments:
        description (str): Description of the model / training or whatever you want to
            save as free text. It saves this string inside the directory with the filename
            &#39;description.txt&#39;.
        dir (str): Path to the directory that will contain the different log files.
    &#34;&#34;&#34;
    if not os.path.exists(directory):
        os.makedirs(directory)

    self.directory = directory
    self.log_file = os.path.join(self.directory, filename)

    if description is not None:
        with open(os.path.join(self.directory, &#39;description.txt&#39;), &#39;w&#39;) as file:
            file.write(description)</code></pre>
</details>
</dd>
<dt id="torchsight.loggers.json.JSONLogger.average_loss"><code class="name flex">
<span>def <span class="ident">average_loss</span></span>(<span>self, key=&#39;loss&#39;, window=1000.0)</span>
</code></dt>
<dd>
<section class="desc"><p>Average the loss with the given window size and show it.</p>
<p>Basically it gets the loss from the log file with the given key, average the values for each
window consecutive times and returns the reduced array.
For example, if we have 1e5 values for the loss and a window size of 1e3 it average each 1e3
losses and return an array with 1e2 values.</p>
<p>If the loss array does not have a multiply of the window size it cuts the oldest values.</p>
<h2 id="return">Return</h2>
<p>torch.Tensor: The tensor with the averaged loss with the given window size.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def average_loss(self, key=&#39;loss&#39;, window=1e3):
    &#34;&#34;&#34;Average the loss with the given window size and show it.

    Basically it gets the loss from the log file with the given key, average the values for each
    window consecutive times and returns the reduced array.
    For example, if we have 1e5 values for the loss and a window size of 1e3 it average each 1e3
    losses and return an array with 1e2 values.

    If the loss array does not have a multiply of the window size it cuts the oldest values.

    Return:
        torch.Tensor: The tensor with the averaged loss with the given window size.
    &#34;&#34;&#34;
    losses = torch.Tensor([float(val) for val in self.read()[key]])

    n_losses = losses.shape[0]
    if n_losses % window != 0:
        losses = losses[int(n_losses % window):]

    losses = losses.view(-1, window)
    return losses.mean(dim=1)</code></pre>
</details>
</dd>
<dt id="torchsight.loggers.json.JSONLogger.epoch_losses"><code class="name flex">
<span>def <span class="ident">epoch_losses</span></span>(<span>self, epoch_key=&#39;epoch&#39;, loss_key=&#39;loss&#39;)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the average loss per each epoch.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>epoch_key</code></strong> :&ensp;<code>str</code></dt>
<dd>The key in the logs dictionary to get the epochs array.</dd>
<dt><strong><code>loss_key</code></strong> :&ensp;<code>str</code></dt>
<dd>The key in the logs dictionary to get the losses array.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>torch.Tensor: The Tensor with the average loss per each epoch.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def epoch_losses(self, epoch_key=&#39;epoch&#39;, loss_key=&#39;loss&#39;):
    &#34;&#34;&#34;Get the average loss per each epoch.

    Arguments:
        epoch_key (str): The key in the logs dictionary to get the epochs array.
        loss_key (str): The key in the logs dictionary to get the losses array.

    Returns:
        torch.Tensor: The Tensor with the average loss per each epoch.
    &#34;&#34;&#34;
    logs = self.read()
    epochs = logs[epoch_key]
    losses = logs[loss_key]
    # Create a dict with the epoch as the key and inside a dict with &#39;sum&#39; and &#39;count&#39;
    epochs_losses = {}
    # Iterate over the logs
    for index, loss in enumerate(losses):
        epoch = epochs[index]
        if epoch not in epochs_losses:
            epochs_losses[epoch] = {&#39;sum&#39;: 0, &#39;total&#39;: 0}
        epochs_losses[epoch][&#39;sum&#39;] += float(loss)
        epochs_losses[epoch][&#39;total&#39;] += 1

    return torch.Tensor([epochs_losses[epoch][&#39;sum&#39;] / epochs_losses[epoch][&#39;total&#39;] for epoch in epochs_losses])</code></pre>
</details>
</dd>
<dt id="torchsight.loggers.json.JSONLogger.get_epochs"><code class="name flex">
<span>def <span class="ident">get_epochs</span></span>(<span>self, epoch_key=&#39;epoch&#39;)</span>
</code></dt>
<dd>
<section class="desc"><p>Return the unique array of epochs.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>epoch_key</code></strong> :&ensp;<code>str</code></dt>
<dd>The key of the epochs in the logs dict.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>list</code></strong></dt>
<dd>The unique list of the epochs number.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_epochs(self, epoch_key=&#39;epoch&#39;):
    &#34;&#34;&#34;Return the unique array of epochs.

    Arguments:
        epoch_key (str): The key of the epochs in the logs dict.

    Returns:
        list: The unique list of the epochs number.
    &#34;&#34;&#34;
    return list(set(self.read()[epoch_key]))</code></pre>
</details>
</dd>
<dt id="torchsight.loggers.json.JSONLogger.log"><code class="name flex">
<span>def <span class="ident">log</span></span>(<span>self, data)</span>
</code></dt>
<dd>
<section class="desc"><p>Log the data.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>dict</code></dt>
<dd>A dict with the data to log.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def log(self, data):
    &#34;&#34;&#34;Log the data.

    Arguments:
        data (dict): A dict with the data to log.
    &#34;&#34;&#34;
    self._print(data)
    self._append(data)</code></pre>
</details>
</dd>
<dt id="torchsight.loggers.json.JSONLogger.read"><code class="name flex">
<span>def <span class="ident">read</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Read the logs from the file (if exists) and return the dict.
If there is no file it returns an empty dict.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>dict</code></strong></dt>
<dd>The json saved with the logs.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def read(self):
    &#34;&#34;&#34;Read the logs from the file (if exists) and return the dict.
    If there is no file it returns an empty dict.

    Returns:
        dict: The json saved with the logs.
    &#34;&#34;&#34;
    if os.path.exists(self.log_file):
        with open(self.log_file, &#39;r&#39;) as file:
            return json.loads(file.read())
    return {}</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="torchsight.loggers" href="index.html">torchsight.loggers</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="torchsight.loggers.json.JSONLogger" href="#torchsight.loggers.json.JSONLogger">JSONLogger</a></code></h4>
<ul class="two-column">
<li><code><a title="torchsight.loggers.json.JSONLogger.__init__" href="#torchsight.loggers.json.JSONLogger.__init__">__init__</a></code></li>
<li><code><a title="torchsight.loggers.json.JSONLogger.average_loss" href="#torchsight.loggers.json.JSONLogger.average_loss">average_loss</a></code></li>
<li><code><a title="torchsight.loggers.json.JSONLogger.epoch_losses" href="#torchsight.loggers.json.JSONLogger.epoch_losses">epoch_losses</a></code></li>
<li><code><a title="torchsight.loggers.json.JSONLogger.get_epochs" href="#torchsight.loggers.json.JSONLogger.get_epochs">get_epochs</a></code></li>
<li><code><a title="torchsight.loggers.json.JSONLogger.log" href="#torchsight.loggers.json.JSONLogger.log">log</a></code></li>
<li><code><a title="torchsight.loggers.json.JSONLogger.read" href="#torchsight.loggers.json.JSONLogger.read">read</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.5.3</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>